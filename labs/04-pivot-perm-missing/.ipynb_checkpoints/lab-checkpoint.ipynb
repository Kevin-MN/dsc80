{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4 – Pivot Tables, Permutation Testing, and Missing Values\n",
    "\n",
    "## DSC 80, Spring 2022\n",
    "\n",
    "### Due Date: Monday, April 25th at 11:59 PM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "Much like in DSC 10, this Jupyter Notebook contains the statements of the problems and provides code and Markdown cells to display your answers to the problems. Unlike DSC 10, the notebook is *only* for displaying a readable version of your final answers. The coding will be done in an accompanying `lab.py` file that is imported into the current notebook.\n",
    "\n",
    "Labs and programming assignments will be graded in (at most) two ways:\n",
    "1. The functions and classes in the accompanying `lab.py` file will be tested (a la DSC 20),\n",
    "2. The notebook may be graded (if it contains free response questions or asks you to draw plots).\n",
    "\n",
    "<span style='color:red'><b>Note: For Lab 4 only, there are no hidden tests!</b></span> The tests you see when you run `grader.check` are the final tests that will determine your grade. In addition, when you submit Lab 4 to Gradescope you will see your final score on the assignment right away. (This is because the lab is due very close to the Midterm Exam.)\n",
    "\n",
    "**Do not change the function names in the `*lab.py` file!**\n",
    "- The functions in the `lab.py` file are how your assignment is graded, and they are graded by their name.\n",
    "- If you changed something you weren't supposed to, just use git to revert! Ask us if you need help with this, or google around for `git revert`.\n",
    "\n",
    "**Tips for working in the notebook**:\n",
    "- The notebooks serve to present the questions and give you a place to present your results for later review.\n",
    "- The notebooks in *lab assignments* are not graded (only the `lab.py` file is submitted and graded).\n",
    "- The notebook serves as a nice environment for 'pre-development' and experimentation before designing your function in your `lab.py` file. You can write code here, but make sure that all of your real work is in the `lab.py` file.\n",
    "\n",
    "**Tips for developing in the `lab.py` file**:\n",
    "- Do not change the function names in the starter code; grading is done using these function names.\n",
    "- Do not change the docstrings in the functions. These are there to tell you if your work is on the right track!\n",
    "- You are encouraged to write your own additional helper functions to solve the lab! \n",
    "- Always document your code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing code from `lab.py`\n",
    "\n",
    "* We import our `lab.py` file that's contained in the same directory as this notebook.\n",
    "* We use the `autoreload` notebook extension to make changes to our `lab.py` file immediately available in our notebook. Without this extension, we would need to restart the notebook kernel to see any changes to `lab.py` in the notebook.\n",
    "    - `autoreload` is necessary because, upon import, `lab.py` is compiled to bytecode (in the directory `__pycache__`). Subsequent imports of `lab` merely import the existing compiled python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import os\n",
    "from datetime import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:red'><b>New: Check <a href=https://campuswire.com/c/G325FA25B/feed/754>this</a> Campuswire post for any clarifications each time you start working on the lab.</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 0 – Mid-Quarter Survey 🙋\n",
    "\n",
    "Course staff, along with the Data Science Student Representatives, have put together a mid-quarter survey that will allow you to share feedback on your experience in DSC 80 so far. It is **entirely anonymous**, so we encourage you to be honest.\n",
    "\n",
    "<br>\n",
    "\n",
    "<center><b><a href=https://docs.google.com/forms/d/e/1FAIpQLSd9k90fGqPKDRAnHjFBEx5kak_VtvYN5Fq5uPv9jyqrryaKeA/viewform>Click here to access the mid-quarter survey.</a></b></center>\n",
    "\n",
    "<br>\n",
    "\n",
    "We'd like to have as many students as possible in the class fill out the survey. **As such, if 80% of the class fills out this survey before the Midterm Exam, then everyone will earn an extra point on the Midterm Exam.** The survey will close before the Midterm Exam. \n",
    "\n",
    "We really appreciate your feedback, thanks! 😊"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Time Series Data\n",
    "\n",
    "Imagine that you own an online store and you'd like to monitor the visits to your site. You've collected some data that you store in `data/login_table.csv`. It contains the information about different login dates and times for different users. Some users are unique, some visited your store multiple times.\n",
    "\n",
    "You need to answer a few questions below in order to understand the login patters of your users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 – Passwords 🔑\n",
    "\n",
    "Write a function `latest_login` which takes in a DataFrame like `login` and outputs a DataFrame indexed by `'Login Id'`, of the login that occurs at the latest time-of-day for each user. Latest time-of-day is as it says: the latest time, **regardless of how recent the day is**. The DataFrame should have just one column, named `'Time'`.\n",
    "\n",
    "For example, if a user always logs in once per day at noon, but her most recent log in happened to be at 8:00PM, then her latest log-in time becomes 8:00PM. Note that the values in your returned DataFrame should only include times, not dates.\n",
    "\n",
    "***Note:*** You do not need to use Python's `datetime` module – instead, use the built-in `pandas` methods for working with times that we introduced in [Lecture 9](https://dsc80.com/resources/lectures/lec09/lec09.html) (though you will need to do a bit more research to fully answer the question). Do not use a `for`-loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cool():return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not convert object to NumPy datetime",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m login \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(fp)\n\u001b[1;32m      3\u001b[0m login[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(login[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 4\u001b[0m login[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimes\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;241m=\u001b[39m \u001b[43mlogin\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextract_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m login \u001b[38;5;241m=\u001b[39m login\u001b[38;5;241m.\u001b[39mdrop(columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m login \u001b[38;5;241m=\u001b[39m login\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogin Id\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmax()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4324\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4328\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4329\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4330\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4331\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4332\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4431\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[1;32m   1080\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m-> 1082\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[0;32m-> 1137\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1140\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1144\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Input \u001b[0;32mIn [38]\u001b[0m, in \u001b[0;36mextract_time\u001b[0;34m(date_time)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_time\u001b[39m(date_time):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatetime64\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate_time\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Could not convert object to NumPy datetime"
     ]
    }
   ],
   "source": [
    "\n",
    "login['Time'] = pd.to_datetime(login['Time'])\n",
    "login['times']  = login['Time'].apply(extract_time)\n",
    "login = login.drop(columns = 'Time')\n",
    "login = login.groupby('Login Id').max()\n",
    "login.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Login Id</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>466</td>\n",
       "      <td>2017-01-07 18:24:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>466</td>\n",
       "      <td>2017-01-07 18:24:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>458</td>\n",
       "      <td>2017-01-07 18:25:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>458</td>\n",
       "      <td>2017-01-07 18:26:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>592</td>\n",
       "      <td>2017-01-07 19:09:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>1307</td>\n",
       "      <td>2018-01-04 10:48:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>1230</td>\n",
       "      <td>2018-01-04 11:22:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>1307</td>\n",
       "      <td>2018-01-04 13:13:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td>1307</td>\n",
       "      <td>2018-01-04 13:13:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>1224</td>\n",
       "      <td>2018-01-04 14:10:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3003 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Login Id                 Time\n",
       "0          466  2017-01-07 18:24:07\n",
       "1          466  2017-01-07 18:24:55\n",
       "2          458  2017-01-07 18:25:18\n",
       "3          458  2017-01-07 18:26:21\n",
       "4          592  2017-01-07 19:09:59\n",
       "...        ...                  ...\n",
       "2998      1307  2018-01-04 10:48:28\n",
       "2999      1230  2018-01-04 11:22:00\n",
       "3000      1307  2018-01-04 13:13:44\n",
       "3001      1307  2018-01-04 13:13:45\n",
       "3002      1224  2018-01-04 14:10:04\n",
       "\n",
       "[3003 rows x 2 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = os.path.join('data', 'login_table.csv')\n",
    "login = pd.read_csv(fp)\n",
    "login#.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Login Id</th>\n",
       "      <th>Time</th>\n",
       "      <th>Times</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>466</td>\n",
       "      <td>18:24:07</td>\n",
       "      <td>2017-01-07 18:24:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>466</td>\n",
       "      <td>18:24:55</td>\n",
       "      <td>2017-01-07 18:24:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>458</td>\n",
       "      <td>18:25:18</td>\n",
       "      <td>2017-01-07 18:25:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>458</td>\n",
       "      <td>18:26:21</td>\n",
       "      <td>2017-01-07 18:26:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>592</td>\n",
       "      <td>19:09:59</td>\n",
       "      <td>2017-01-07 19:09:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>1307</td>\n",
       "      <td>10:48:28</td>\n",
       "      <td>2018-01-04 10:48:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>1230</td>\n",
       "      <td>11:22:00</td>\n",
       "      <td>2018-01-04 11:22:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>1307</td>\n",
       "      <td>13:13:44</td>\n",
       "      <td>2018-01-04 13:13:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td>1307</td>\n",
       "      <td>13:13:45</td>\n",
       "      <td>2018-01-04 13:13:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>1224</td>\n",
       "      <td>14:10:04</td>\n",
       "      <td>2018-01-04 14:10:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3003 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Login Id      Time               Times\n",
       "0          466  18:24:07 2017-01-07 18:24:07\n",
       "1          466  18:24:55 2017-01-07 18:24:55\n",
       "2          458  18:25:18 2017-01-07 18:25:18\n",
       "3          458  18:26:21 2017-01-07 18:26:21\n",
       "4          592  19:09:59 2017-01-07 19:09:59\n",
       "...        ...       ...                 ...\n",
       "2998      1307  10:48:28 2018-01-04 10:48:28\n",
       "2999      1230  11:22:00 2018-01-04 11:22:00\n",
       "3000      1307  13:13:44 2018-01-04 13:13:44\n",
       "3001      1307  13:13:45 2018-01-04 13:13:45\n",
       "3002      1224  14:10:04 2018-01-04 14:10:04\n",
       "\n",
       "[3003 rows x 3 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_login(login)#.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "times    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "login.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell -- it is needed for the tests to work\n",
    "fp = os.path.join('data', 'login_table.csv')\n",
    "login = pd.read_csv(fp)\n",
    "q1_result = latest_login(login)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong style='color: red;'><pre style='display: inline;'>q1</pre> results:</strong></p><p><strong><pre style='display: inline;'>q1 - 1</pre> result:</strong></p><pre>    Test case passed!</pre><p><strong><pre style='display: inline;'>q1 - 2</pre> result:</strong></p><pre>    Test case passed!</pre><p><strong><pre style='display: inline;'>q1 - 3</pre> result:</strong></p><pre>    Test case passed!</pre><p><strong><pre style='display: inline;'>q1 - 4</pre> result:</strong></p><pre>    Trying:\n",
       "        q1_result.loc[457, 'Time'] == time(18, 41, 13)\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q1 3\n",
       "    Failed example:\n",
       "        q1_result.loc[457, 'Time'] == time(18, 41, 13)\n",
       "    Expected:\n",
       "        True\n",
       "    Got:\n",
       "        False\n",
       "</pre><p><strong><pre style='display: inline;'>q1 - 4</pre> message:</strong> check user 457</p><p><strong><pre style='display: inline;'>q1 - 5</pre> result:</strong></p><pre>    Trying:\n",
       "        q1_result.loc[457, 'Time'].hour > 12\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q1 4\n",
       "    Failed example:\n",
       "        q1_result.loc[457, 'Time'].hour > 12\n",
       "    Expected:\n",
       "        True\n",
       "    Got:\n",
       "        False\n",
       "</pre><p><strong><pre style='display: inline;'>q1 - 5</pre> message:</strong> check user 457</p><p><strong><pre style='display: inline;'>q1 - 6</pre> result:</strong></p><pre>    Test case passed!</pre><p><strong><pre style='display: inline;'>q1 - 7</pre> result:</strong></p><pre>    Trying:\n",
       "        q1_result.loc[381, 'Time'] == time(22, 51, 15)\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q1 6\n",
       "    Failed example:\n",
       "        q1_result.loc[381, 'Time'] == time(22, 51, 15)\n",
       "    Expected:\n",
       "        True\n",
       "    Got:\n",
       "        False\n",
       "</pre><p><strong><pre style='display: inline;'>q1 - 7</pre> message:</strong> check user 381</p><p><strong><pre style='display: inline;'>q1 - 8</pre> result:</strong></p><pre>    Trying:\n",
       "        q1_result.loc[381, 'Time'].hour > 20\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q1 7\n",
       "    Failed example:\n",
       "        q1_result.loc[381, 'Time'].hour > 20\n",
       "    Expected:\n",
       "        True\n",
       "    Got:\n",
       "        False\n",
       "</pre><p><strong><pre style='display: inline;'>q1 - 8</pre> message:</strong> check user 381</p><p><strong><pre style='display: inline;'>q1 - 9</pre> result:</strong></p><pre>    Trying:\n",
       "        np.isclose(q1_result.loc[:, 'Time'].apply(lambda x: x.minute).mean(), 29.79, atol=0.5)\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q1 8\n",
       "    Failed example:\n",
       "        np.isclose(q1_result.loc[:, 'Time'].apply(lambda x: x.minute).mean(), 29.79, atol=0.5)\n",
       "    Expected:\n",
       "        True\n",
       "    Got:\n",
       "        False\n",
       "</pre><p><strong><pre style='display: inline;'>q1 - 9</pre> message:</strong> check the entire list of times</p><p><strong><pre style='display: inline;'>q1 - 10</pre> result:</strong></p><pre>    Test case passed!</pre><p><strong><pre style='display: inline;'>q1 - 11</pre> result:</strong></p><pre>    Trying:\n",
       "        np.isclose(q1_result.loc[:, 'Time'].apply(lambda x: x.hour).median(),16, atol=0)\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q1 10\n",
       "    Failed example:\n",
       "        np.isclose(q1_result.loc[:, 'Time'].apply(lambda x: x.hour).median(),16, atol=0)\n",
       "    Expected:\n",
       "        True\n",
       "    Got:\n",
       "        False\n",
       "</pre><p><strong><pre style='display: inline;'>q1 - 11</pre> message:</strong> median hour: approx</p><p><strong><pre style='display: inline;'>q1 - 12</pre> result:</strong></p><pre>    Trying:\n",
       "        q1_result.loc[:, 'Time'].min() == time(1, 5, 43)\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q1 11\n",
       "    Failed example:\n",
       "        q1_result.loc[:, 'Time'].min() == time(1, 5, 43)\n",
       "    Expected:\n",
       "        True\n",
       "    Got:\n",
       "        False\n",
       "</pre><p><strong><pre style='display: inline;'>q1 - 12</pre> message:</strong> check the earliest time</p><p><strong><pre style='display: inline;'>q1 - 13</pre> result:</strong></p><pre>    Trying:\n",
       "        int(q1_result.loc[:, 'Time'].min().hour) == 1\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q1 12\n",
       "    Failed example:\n",
       "        int(q1_result.loc[:, 'Time'].min().hour) == 1\n",
       "    Expected:\n",
       "        True\n",
       "    Got:\n",
       "        False\n",
       "</pre><p><strong><pre style='display: inline;'>q1 - 13</pre> message:</strong> check the earliest time: hour</p>"
      ],
      "text/plain": [
       "q1 results:\n",
       "    q1 - 1 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q1 - 2 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q1 - 3 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q1 - 4 result:\n",
       "        Trying:\n",
       "            q1_result.loc[457, 'Time'] == time(18, 41, 13)\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q1 3\n",
       "        Failed example:\n",
       "            q1_result.loc[457, 'Time'] == time(18, 41, 13)\n",
       "        Expected:\n",
       "            True\n",
       "        Got:\n",
       "            False\n",
       "\n",
       "    q1 - 4 message: check user 457\n",
       "\n",
       "    q1 - 5 result:\n",
       "        Trying:\n",
       "            q1_result.loc[457, 'Time'].hour > 12\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q1 4\n",
       "        Failed example:\n",
       "            q1_result.loc[457, 'Time'].hour > 12\n",
       "        Expected:\n",
       "            True\n",
       "        Got:\n",
       "            False\n",
       "\n",
       "    q1 - 5 message: check user 457\n",
       "\n",
       "    q1 - 6 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q1 - 7 result:\n",
       "        Trying:\n",
       "            q1_result.loc[381, 'Time'] == time(22, 51, 15)\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q1 6\n",
       "        Failed example:\n",
       "            q1_result.loc[381, 'Time'] == time(22, 51, 15)\n",
       "        Expected:\n",
       "            True\n",
       "        Got:\n",
       "            False\n",
       "\n",
       "    q1 - 7 message: check user 381\n",
       "\n",
       "    q1 - 8 result:\n",
       "        Trying:\n",
       "            q1_result.loc[381, 'Time'].hour > 20\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q1 7\n",
       "        Failed example:\n",
       "            q1_result.loc[381, 'Time'].hour > 20\n",
       "        Expected:\n",
       "            True\n",
       "        Got:\n",
       "            False\n",
       "\n",
       "    q1 - 8 message: check user 381\n",
       "\n",
       "    q1 - 9 result:\n",
       "        Trying:\n",
       "            np.isclose(q1_result.loc[:, 'Time'].apply(lambda x: x.minute).mean(), 29.79, atol=0.5)\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q1 8\n",
       "        Failed example:\n",
       "            np.isclose(q1_result.loc[:, 'Time'].apply(lambda x: x.minute).mean(), 29.79, atol=0.5)\n",
       "        Expected:\n",
       "            True\n",
       "        Got:\n",
       "            False\n",
       "\n",
       "    q1 - 9 message: check the entire list of times\n",
       "\n",
       "    q1 - 10 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q1 - 11 result:\n",
       "        Trying:\n",
       "            np.isclose(q1_result.loc[:, 'Time'].apply(lambda x: x.hour).median(),16, atol=0)\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q1 10\n",
       "        Failed example:\n",
       "            np.isclose(q1_result.loc[:, 'Time'].apply(lambda x: x.hour).median(),16, atol=0)\n",
       "        Expected:\n",
       "            True\n",
       "        Got:\n",
       "            False\n",
       "\n",
       "    q1 - 11 message: median hour: approx\n",
       "\n",
       "    q1 - 12 result:\n",
       "        Trying:\n",
       "            q1_result.loc[:, 'Time'].min() == time(1, 5, 43)\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q1 11\n",
       "        Failed example:\n",
       "            q1_result.loc[:, 'Time'].min() == time(1, 5, 43)\n",
       "        Expected:\n",
       "            True\n",
       "        Got:\n",
       "            False\n",
       "\n",
       "    q1 - 12 message: check the earliest time\n",
       "\n",
       "    q1 - 13 result:\n",
       "        Trying:\n",
       "            int(q1_result.loc[:, 'Time'].min().hour) == 1\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q1 12\n",
       "        Failed example:\n",
       "            int(q1_result.loc[:, 'Time'].min().hour) == 1\n",
       "        Expected:\n",
       "            True\n",
       "        Got:\n",
       "            False\n",
       "\n",
       "    q1 - 13 message: check the earliest time: hour"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 – Return Users 🔁\n",
    "\n",
    "As a site owner, you would like to see how often users return to your site. You've noticed that there are users who have several logins and users who logged in only once. Of those users that logged in more than once, you are interested in finding the shortest amount of time elapsed between two consecutive logins for each of these users.\n",
    "\n",
    "Write a function `smallest_elapsed` which takes in a DataFrame like `login` and outputs a DataFrame, indexed by `'Login ID'`, containing the shortest time elapsed for each user. Any users who haven't logged in more than once should not be included in the output. Your DataFrame should only have a single column, named `'Time'`.\n",
    "\n",
    "***Hint:*** You need not do any querying for this question. There is a built-in `numpy`/`pandas` method that you can use to find the smallest elapsed time for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# don't change this cell -- it is needed for the tests to work\n",
    "fp = os.path.join('data', 'login_table.csv')\n",
    "login = pd.read_csv(fp)\n",
    "q2_result = smallest_elapsed(login)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Pivot Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 – Summarizing Sales 💰\n",
    "\n",
    "Recall from [Lecture 8](https://dsc80.com/resources/lectures/lec08/lec08.html), a pivot table allows you to aggregate the entries in a DataFrame based on two categorical columns. In this question, you are given a simple dataset, `data/sales.csv`, and are asked to solve a few simple problems using the `pivot_table` method.  \n",
    "\n",
    "We have provided the outline for your DataFrames, but yours may have a different number of rows and columns and different values.\n",
    "\n",
    "#### `total_seller`\n",
    "\n",
    "Write a function `total_seller` that takes in the `sales` DataFrame and returns a DataFrame that contains the total sales for each seller, indexed by `'Name'`. There should not be any `NaN`s.\n",
    "\n",
    "***Note:*** You may be able to implement `total_seller` without using `pivot_table`.\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>Total</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Name</th>\n",
    "      <th></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>Jones</th>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Smith</th>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Trump</th>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `product_name`\n",
    "\n",
    "Write a function `product_name` that takes in the `sales` DataFrame and returns a DataFrame that contains the total sales for each seller, indexed by `'Product'`. Do not fill in `NaN`s.\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Name</th>\n",
    "      <th>Jones</th>\n",
    "      <th>Smith</th>\n",
    "      <th>Trump</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Product</th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>boat</th>\n",
    "      <td>NaN</td>\n",
    "      <td>NaN</td>\n",
    "      <td>0.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>book</th>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>hotel</th>\n",
    "      <td>NaN</td>\n",
    "      <td>NaN</td>\n",
    "      <td>0.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>pen</th>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>ruler</th>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>NaN</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `count_product`\n",
    "\n",
    "Write a function `count_product` that takes in the `sales` DataFrame and returns a DataFrame that contains the total number of items sold product-wise and name-wise per date. Replace `NaN`s with 0s. Don't reset the index after pivoting.\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th></th>\n",
    "      <th>Date</th>\n",
    "      <th>01.01.2012</th>\n",
    "      <th>02.20.2013</th>\n",
    "      <th>02.25.2015</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Product</th>\n",
    "      <th>Name</th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>boat</th>\n",
    "      <th>Trump</th>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th rowspan=\"3\" valign=\"top\">book</th>\n",
    "      <th>Jones</th>\n",
    "      <td>0</td>\n",
    "      <td>1</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Smith</th>\n",
    "      <td>1</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Trump</th>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>hotel</th>\n",
    "      <th>Trump</th>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `product_name`\n",
    "\n",
    "Write a function `total_by_month` that takes in the `sales` DataFrame and returns a pivot table that contains the total sales name-wise, product-wise per month. Replace `NaN`s with 0s. Don't reset the index after pivoting.\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th></th>\n",
    "      <th>Month</th>\n",
    "      <th>February</th>\n",
    "      <th>January</th>\n",
    "      <th>July</th>\n",
    "      <th>March</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Name</th>\n",
    "      <th>Product</th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th rowspan=\"3\" valign=\"top\">Jones</th>\n",
    "      <th>book</th>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>pen</th>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>ruler</th>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th rowspan=\"3\" valign=\"top\">Smith</th>\n",
    "      <th>book</th>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>pen</th>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>ruler</th>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "***Note:*** [Here](https://jakevdp.github.io/PythonDataScienceHandbook/03.09-pivot-tables.html) is another great resource that provides an overview of `pivot_table` with many examples from the Titanic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell -- it is needed for the tests to work\n",
    "fp = os.path.join('data', 'sales.csv')\n",
    "sales = pd.read_csv(fp)\n",
    "q3_total_seller_out = total_seller(sales)\n",
    "q3_product_name_out = product_name(sales)\n",
    "q3_product_count_out = count_product(sales)\n",
    "q3_total_by_month_out = total_by_month(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Permutation Testing\n",
    "\n",
    "[Skittles](https://en.wikipedia.org/wiki/Skittles_(confectionery)) 🍬 are made in two locations in the United States: Yorkville, Illinois and Waco, Texas. In these factories, Skittles of different colors are made separately by different machines and combined/packaged into bags for sale. The **tab-separated file** `data/skittles.tsv` contains the contents of 468 bags of Skittles.\n",
    "\n",
    "Throughout this question, we will compare the color distribution of Skittles between bags made in the Yorkville factory and bags made in the Waco factory. Most people have preferences for their favorite flavor and there is a surprising amount of variation among the distribution of flavors in each bag.\n",
    "\n",
    "Look at the variation by bag in the dataset below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skittles_fp = os.path.join('data', 'skittles.tsv')\n",
    "skittles = pd.read_csv(skittles_fp, sep='\\t')\n",
    "skittles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skittles.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 – Orange Skittles 🟠\n",
    "\n",
    "First, you will investigate if the machine that mixes together the Skittles of different colors might favor one color over another. Use a permutation test to assess whether, on average, bags made in Yorkville have the same number of orange skittles as bags made in Waco. Do this by implementing the functions described below.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `diff_of_means`\n",
    "\n",
    "Create a function `diff_of_means` that takes in a DataFrame like `skittles` and returns the **absolute difference** between the **mean** number of orange Skittles per bag from Yorkville and the **mean** number of orange Skittles per bag from Waco.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `simulate_null`\n",
    "\n",
    "Create a function `simulate_null` that takes in a DataFrame like `skittles` and returns one simulated instance of the test statistic under the null hypothesis. Note that this will involve shuffling!\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `pval_color`\n",
    "\n",
    "Create a function `pval_color` that takes in a DataFrame like `skittles` and calculates the p-value for the permutation test using 1000 trials.\n",
    "\n",
    "<br>\n",
    "\n",
    "Plot the observed statistic, along with the histogram for the simulated distribution, to check your work.\n",
    "\n",
    "***Note:*** In all functions, the default argument for `col` is `'orange'`. Your functions should still work for any color so that you can call it in later questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell -- it is needed for the tests to work\n",
    "skittles_fp = os.path.join('data', 'skittles.tsv')\n",
    "skittles = pd.read_csv(skittles_fp, sep='\\\\t', engine='python')\n",
    "q4_diff_of_means_out = diff_of_means(skittles)\n",
    "q4_simulate_null_out = simulate_null(skittles)\n",
    "q4_many_diffs = np.array([simulate_null(skittles) for _ in range(100)])\n",
    "q4_pval_out = pval_color(skittles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 – Generalizing to all colors 🔴🟠🟡🟢🟣\n",
    "\n",
    "While your `pval_color` function used a default color of `'orange'`, it should also work for all other colors of Skittles, meaning you can run the same permutation test from Question 4 on all colors of Skittles. Call `pval_color` on all colors of Skittles to find which colors differ the most between the two locations on average. \n",
    "\n",
    "Then, create a function `ordered_colors` that returns a list of five ordered pairs, each of the form `('color', p_value)`. For example, your list might look like `[('pink', 0.000), ('brown', 0.025), ...]`. \n",
    "\n",
    "The list should be **hard-coded**, meaning that you should run your permutation tests in your notebook, not in your `.py` file. The list should also be sorted in **increasing order of p-value**. Make sure your p-values are rounded to **3 decimal places**.\n",
    "\n",
    "Even though there is randomness in the color composition in each bag, this list gives the likelihood that the machines have a systematic, meaningful, difference in how they blend the colors in each bag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell -- it is needed for the tests to work\n",
    "q5_out = ordered_colors()\n",
    "q5_colors = {'green', 'orange', 'purple', 'red', 'yellow'}\n",
    "q5_test_colors = [x[0] for x in q5_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6 – Overall distributions 🏭\n",
    "\n",
    "Now, suppose you would like to assess whether the two locations make similar amounts of each color overall. That is, suppose we:\n",
    "* Combine and count up all the Skittles of each color that were made in Yorkville (e.g. 14303 total red skittles, 9091 total green skittles, etc.)\n",
    "* Combine and count up all the Skittles of each color that were made in Waco.\n",
    "\n",
    "**Are these distributions of colors similar?** Is the variation among the bags due to each factory making different amounts of each color?\n",
    "\n",
    "Use a permutation test to assess whether the distribution of colors of Skittles made in Yorkville is statistically significantly different than those made in Waco. Set a significance level of 0.01 and determine whether you can reject a null hypothesis that answers the question above using a permutation test with 1000 trials. For your test statistic, use the **total variation distance (TVD)**.\n",
    "\n",
    "Refer to [Lecture 10](https://dsc80.com/resources/lectures/lec10/lec10.html) to see an example of a [permutation test](https://www.inferentialthinking.com/chapters/12/Comparing_Two_Samples.html) that uses the [TVD](https://inferentialthinking.com/chapters/11/2/Multiple_Categories.html) as the test statistic. Some guidance:\n",
    "\n",
    "- Our previous permutation tests have compared the mean number of (say) orange Skittles in Yorkville bags to the mean number of orange Skittles in Waco bags. The role of shuffling was to randomly assign bags to Yorkville and Waco.\n",
    "- In this permutation test, we are **still** shuffling to randomly assign bags to Yorkville and Waco. The only difference is that after we randomly assign each bag to a factory, we will compute the distribution of colors amongst the two factories and find the TVD between those two distributions.\n",
    "\n",
    "**Your job:** Create a function `same_color_distribution` that takes in no arguments and outputs a hard-coded **tuple** with the p-value and whether you `'Fail to Reject'` or `'Reject'` the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell -- it is needed for the tests to work\n",
    "q6_out = same_color_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7 – Permutation testing vs. hypothesis testing 🧪\n",
    "\n",
    "In each of the following scenarios, decide  whether  a  permutation test is appropriate to determine if there is a  significant difference between the quantities described. If a permutation test is appropriate, mark `'P'`. Otherwise, mark `'H'`.\n",
    "\n",
    "Record your answers in the function `perm_vs_hyp` that outputs a list of length 5, containing the values `'P'` and `'H'`.\n",
    "\n",
    "1. Compare the DSC 80 pass rate between second years and third years who take the class.\n",
    "2. Compare the proportion of Data Science majors who have completed DSC 80 and the proportion of Data Science minors who have completed DSC 80.\n",
    "3. Compare the proportion of students who have iPhones to the proportion of students who have Android phones (for simplicity, assume that all students either have an iPhone or an Android).\n",
    "4. In DSC 80, we ask all students whether they liked DSC 40A or DSC 40B more. Compare the proportion of students who preferred DSC 40A to the proportion who preferred DSC 40B.\n",
    "5. Compare the attendance rate of classes that play music before class vs. classes that do not play music before class.\n",
    "\n",
    "***Hint:*** Think about the type of data you would collect in each case, and how you would simulate new data under the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell -- it is needed for the tests to work\n",
    "q7_out = perm_vs_hyp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Types of Missingness\n",
    "\n",
    "First, let's recap the different mechanisms of missingness we studied in lecture.\n",
    "\n",
    "### Missing by Design (MD)\n",
    "- The missing field is deliberately missing. The missing field is deliberately set to null or not collected (hence, \"missing by design\").\n",
    "- The missingness can be exactly predicted when a column will be null, with only knowledge of the other columns using a function of the rows of the dataset.\n",
    "\n",
    "### Missing Completely at Random (MCAR)\n",
    "- The missingness of missing value isn't related to the actual, unreported value itself, nor the values in any other fields. The missingness is not systematic.\n",
    "- The missingness is unconditionally uniform across rows. MCAR doesn't bias the observed data.\n",
    "- There is no relationship between the missing data and the any of the other data, observed or missing.\n",
    "\n",
    "### Missing at Random (MAR)\n",
    "- The missingness of the missing value has nothing to do with the value itself, but may be related to another field.\n",
    "- The missingness is uniform across rows, perhaps conditional on another column. MAR biases the observed data, but is fixable.\n",
    "- There is a systematic relationship between the missing values and the observed data (but not the missing values themselves).\n",
    "- Difference between MD and MAR: If you can *exactly/always* determine missingness using the other columns, the missingness is MD. If there is just some sort of systematic relationship between the missing columns/values and other columns/values that may help us predict missingness, the missingness is MAR.\n",
    "\n",
    "### Non-Ignorable (NI, aka NMAR)\n",
    "- The missingness of the missing value is related to the actual, unreported value.\n",
    "- NI biases the observed data in unobservable ways.\n",
    "- There is relationship between the propensity of a value to be missing and its value.\n",
    "- ***Note:*** In lecture, we referred to non-ignorable missingness as \"not missing at random (NMAR)\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8 – After-purchase surveys 🛒\n",
    "\n",
    "You run a small e-commerce website and send surveys out to customers after they purchase an item from your store. The survey asks whether the customer is satisfied with their purchase (\"Yes\" or \"No\"). Below, you are presented with possible datasets, each of which contains a column `'satisfied'` as described above, as well as a `'customer_id'` number corresponding to the customer and an `'item'` column describing the item that the customer purchased. **The column `'satisfied'` is missing data.**\n",
    "\n",
    "For each of the following datasets, label the column `'satisfied'` as being `'MD'`, `'MCAR'`, `'MAR'`, or `'NI'`.\n",
    "\n",
    "1. The dataset consists only of the columns `'customer_id'` and `'satisfied'`.\n",
    "2. The dataset contains the `'customer_id'` of every customer with an account, even if they didn't make a purchase. Also, in this case, you notice everyone who was sent a survey filled it out.\n",
    "3. The dataset contains a column specifying if the user later returned the item.\n",
    "4. The dataset contains a column with the serial number for the item purchased.\n",
    "5. The dataset contains a column with the price of the item purchased.\n",
    "\n",
    "Record your answers in the function `after_purchase` that outputs a list of length 5, containing the values `'MD'`, `'MCAR'`, `'MAR'`, or `'NI'`. For some questions there may be multiple good answers, but there is generally one answer that is \"best\". If you are unsure, ask a tutor, but be prepared to provide justification for whichever answer(s) you think might be right.\n",
    "\n",
    "***Disclaimer:*** We know that this lab has no hidden tests, and so it is possible to just look at the correct answers by running `grader.check`. This is not a good idea – you should really think about all of the questions here, since similar questions will be on the Midterm Exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell -- it is needed for the tests to work\n",
    "q8_out = after_purchase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9 – Miscellaneous missingness questions 🕵️\n",
    "\n",
    "In each of the following scenarios, choose the best answer out of the missingness types: `'MD'`, `'MCAR'`, `'MAR'`, and `'NI'`. Store your answers in a list of length 5, and have the function `multiple_choice` return that list.\n",
    "\n",
    "1. UCSD has recently adopted GrubHub as the food pre-ordering app for campus restaurants, so you can order your food ahead of time and stop by before your next class. In a DataFrame of GrubHub app orders, which contains information such as `'restaurant'`, `'name'`, `'items'`, and `'total'`, the column `'delivery_address'` is often missing for UCSD students. Which is the most likely missingness mechanism for this column?\n",
    "\n",
    "\n",
    "2. In a database of student records that records student profile data, such as `'name'`, `'home_address'`, `'ethnicity'`, etc., sometimes the `'middle_name'` column is missing. Which is the most likely missingness mechanism for this column?\n",
    "\n",
    "\n",
    "3. The UCSD Club Basketball team creates a signup sheet for potential new members. The sheet contains the columns `'full_name'`, `'year'`, `'email'`, `'favorite_sports'`, `'number_of_sports_played'`, and `'sports_previously_played'`. The team president notices that many students left the `'sports_previously_played'` column blank. Which is the most likely missingness mechanism for this column?\n",
    "\n",
    "\n",
    "4. After the 2022 Sun God Festival, Associated Students sends out a survey to all students about whether their expectations for the 2022 Sun God Festival were met, with all questions being optional. They notice that many students left the \"Were you satisfied with the 2022 Sun God Festival?\" question blank. Which is the most likely missingness mechanism for answers to this question?\n",
    "\n",
    "\n",
    "5. UCSD has been using a two-factor authentication system, DUO, since October 16th, 2019. When using DUO, all UCSD accounts are assigned a unique code. UCSD's Service Desk, who maintains DUO, has a database that stores each user's code and their phone number, which users must provide when they sign up for DUO. They notice that many phone numbers are missing. Which is the most likely missingness mechanism for phone numbers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell -- it is needed for the tests to work\n",
    "q9_out = multiple_choice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You're done! 🏁\n",
    "\n",
    "Submit your `lab.py` file to Gradescope. Note that you only need to submit the `lab.py` file; this notebook should not be uploaded.\n",
    "\n",
    "Before submitting, you should ensure that all of your work is in the `lab.py` file. You can do this by running the doctests below, which will verify that your work passes the public tests **and** that your work is in the `lab.py` file. Run the cell below; you should see no output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m doctest lab.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, `grader.check_all()` will verify that your work passes the public tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "nteract": {
   "version": "0.15.0"
  },
  "otter": {
   "tests": {
    "q1": {
     "name": "q1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(q1_result) == 433\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q1_result.loc[381, \"Time\"].hour > 12\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> import util\n>>> not util.check_loops(latest_login)\nTrue",
         "failure_message": "You should not use loops in Pandas. Loop was found in latest_login.",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q1_result.loc[457, 'Time'] == time(18, 41, 13)\nTrue",
         "failure_message": "check user 457",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q1_result.loc[457, 'Time'].hour > 12\nTrue",
         "failure_message": "check user 457",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> len(set(q1_result.index)) == 433\nTrue",
         "failure_message": "check number of unique users",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q1_result.loc[381, 'Time'] == time(22, 51, 15)\nTrue",
         "failure_message": "check user 381",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q1_result.loc[381, 'Time'].hour > 20\nTrue",
         "failure_message": "check user 381",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> np.isclose(q1_result.loc[:, 'Time'].apply(lambda x: x.minute).mean(), 29.79, atol=0.5)\nTrue",
         "failure_message": "check the entire list of times",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(q1_result.loc[:, 'Time'].apply(lambda x: x.hour).median(), 16, atol=2.0)\nTrue",
         "failure_message": "median hour: approx",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(q1_result.loc[:, 'Time'].apply(lambda x: x.hour).median(),16, atol=0)\nTrue",
         "failure_message": "median hour: approx",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q1_result.loc[:, 'Time'].min() == time(1, 5, 43)\nTrue",
         "failure_message": "check the earliest time",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> int(q1_result.loc[:, 'Time'].min().hour) == 1\nTrue",
         "failure_message": "check the earliest time: hour",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(q2_result) == 238\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> 18 < q2_result.loc[1233, \"Time\"].days < 23\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> import util\n>>> not util.check_loops(smallest_elapsed)\nTrue",
         "failure_message": "You should not use loops in Pandas. Loop was found in smallest_elapsed.",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q2_result['Time'].dt.days.max() == 118\nTrue",
         "failure_message": "max number of days in table",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> (q2_result['Time'].dt.days == 0).sum() == 172\nTrue",
         "failure_message": "number of people who visited twice in a day",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> 165 <= (q2_result['Time'].dt.days == 0).sum() <= 180\nTrue",
         "failure_message": "number of people who visited twice in a day: approx",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> 64 <= (q2_result['Time'].dt.days > 0).sum() <= 68\nTrue",
         "failure_message": "number of people who never visited twice in a day: approx",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> 18 < q2_result.loc[1233, \"Time\"].days < 23\nTrue",
         "failure_message": "check index 1233",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q2_result['Time'].dt.days.max() >= 100\nTrue",
         "failure_message": "max number of days in table: approx",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> 50 <= (q2_result['Time'].dt.days > 0).sum() <= 80\nTrue",
         "failure_message": "number of people who never visited twice in a day: approx",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> 8 < q2_result.loc[1233, \"Time\"].days < 30\nTrue",
         "failure_message": "check index 1233: approx",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> len(q2_result) == 238\nTrue",
         "failure_message": "doctest",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> 18 < q2_result.loc[1233, \"Time\"].days < 23\nTrue",
         "failure_message": "doctest",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> q3_total_seller_out.shape[0] == 3\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q3_total_seller_out[\"Total\"].sum() < 15000\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q3_product_name_out.size == 15\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q3_product_name_out.loc[\"pen\"].isnull().sum() == 0\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q3_product_count_out.loc[\"boat\"].loc[\"Trump\"].value_counts()[0] == 6\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q3_product_count_out.size == 70\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q3_total_by_month_out[\"May\"].idxmax() == ('Smith', 'book')\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q3_total_by_month_out.shape[1] == 5\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> import util\n>>> not util.check_loops(total_seller)\nTrue",
         "failure_message": "You should not use loops in Pandas. Loop was found in total_seller.",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> import util\n>>> not util.check_loops(product_name)\nTrue",
         "failure_message": "You should not use loops in Pandas. Loop was found in product_name.",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> import util\n>>> not util.check_loops(count_product)\nTrue",
         "failure_message": "You should not use loops in Pandas. Loop was found in count_product.",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> import util\n>>> not util.check_loops(total_by_month)\nTrue",
         "failure_message": "You should not use loops in Pandas. Loop was found in total_by_month.",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> q3_total_seller_out.loc['Smith', 'Total'] == 6800\nTrue",
         "failure_message": "Smith Total",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q3_total_seller_out.loc['Jones', 'Total'] == 3680\nTrue",
         "failure_message": "Jones Total",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> int(q3_product_name_out.loc['boat', 'Trump']) == 700\nTrue",
         "failure_message": "boat / Trump",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> int(q3_product_name_out.loc['ruler', 'Smith']) == 2100\nTrue",
         "failure_message": "ruler / Smith",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> int(q3_product_name_out.loc['hotel'].isnull().sum()) == 2\nTrue",
         "failure_message": "null values: hotel row",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q3_product_count_out.shape == (10, 7)\nTrue",
         "failure_message": "correct shape",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> (q3_product_count_out == 0).sum().sum() == 58\nTrue",
         "failure_message": "Total number of 0 entries.",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> int(q3_total_by_month_out.loc[('Smith', 'book'), 'May']) == 2000\nTrue",
         "failure_message": "books for smith in May",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> (q3_total_by_month_out > 2000).sum().sum() == 3\nTrue",
         "failure_message": "number of entries strictly over 2000",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> (q3_total_by_month_out == 0).sum().sum() == 39\nTrue",
         "failure_message": "number of zero entries",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 0 <= q4_diff_of_means_out\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> isinstance(q4_simulate_null_out, float)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> 0 <= q4_simulate_null_out <= 1.0\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> isinstance(q4_pval_out, float)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> 0 <= q4_pval_out <= 0.1\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q4_diff_of_means_out > 0\nTrue",
         "failure_message": "greater than zero",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(q4_diff_of_means_out, 0.6004398826979482, atol=0.1)\nTrue",
         "failure_message": "answer: approx within 0.1",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(q4_diff_of_means_out, 0.6004398826979482, atol=0.01)\nTrue",
         "failure_message": "answer: approx within 0.01",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> (q4_simulate_null_out >= 0).all()\nTrue",
         "failure_message": "greater than zero",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(q4_many_diffs.mean(), 0.22, atol=0.6)\nTrue",
         "failure_message": "answer: mean null distribution near 0.22",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(q4_many_diffs.mean(), 0.22, atol=0.1)\nTrue",
         "failure_message": "answer: mean null distribution near 0.22, approx",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> 0 <= q4_pval_out <= 1\nTrue",
         "failure_message": "orange p-value: doctest",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(q4_pval_out, 0.049, atol=0.05)\nTrue",
         "failure_message": "orange p-value: within 0.05",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(q4_pval_out, 0.049, atol=0.075)\nTrue",
         "failure_message": "orange p-value: approx: within 0.075",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(q4_pval_out, 0.049, atol=0.1)\nTrue",
         "failure_message": "orange p-value: approx",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(q5_out) == 5\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> set([x[0] for x in q5_out]) == q5_colors\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> all([isinstance(x[1], float) for x in q5_out])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q5_test_colors.index('yellow') < q5_test_colors.index('orange')\nTrue",
         "failure_message": "yellow less than orange",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q5_test_colors.index('orange') < q5_test_colors.index('red')\nTrue",
         "failure_message": "orange less than red",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q5_test_colors.index('red') < q5_test_colors.index('green')\nTrue",
         "failure_message": "red less than green",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q5_test_colors.index('green') < q5_test_colors.index('purple')\nTrue",
         "failure_message": "green less than purple",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(q5_out[0][1], 0.000)\nTrue",
         "failure_message": "smallest pval",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(q5_out[1][1], 0.035, atol=0.05)\nTrue",
         "failure_message": "2nd pval",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(q5_out[2][1], 0.241, atol=0.05)\nTrue",
         "failure_message": "3rd pval",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(q5_out[3][1], 0.450, atol=0.05)\nTrue",
         "failure_message": "4th pval",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(q5_out[4][1], 0.964, atol=0.05)\nTrue",
         "failure_message": "largest pval",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6": {
     "name": "q6",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(q6_out, tuple)\nFalse",
         "failure_message": "tuple",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> isinstance(q6_out[0], float)\nTrue",
         "failure_message": "wrong output type at index 0",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q6_out[1] in ['Fail to Reject', 'Reject']\nTrue",
         "failure_message": "wrong output type at index 1",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> cond1 = q6_out[1] == 'Reject'\n>>> cond2 = (q6_out[0] > 0.01) and (q6_out[1] == 'Fail to Reject')\n>>> cond1 or cond2\nTrue",
         "failure_message": "reject the null hypothesis",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(q6_out[0], 0.005, atol=0.1)\nTrue",
         "failure_message": "p-value, approximate within 0.1",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(q6_out[0], 0.005, atol=0.05)\nTrue",
         "failure_message": "p-value, approximate within 0.05",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(q6_out[0], 0.005, atol=0.01)\nTrue",
         "failure_message": "p-value, approximate within 0.01",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(q6_out[0], 0.005, atol=0.25)\nTrue",
         "failure_message": "p-value, approximate within 0.25",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(q6_out[0], 0.005, atol=0.5)\nTrue",
         "failure_message": "p-value, approximate within 0.5",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7": {
     "name": "q7",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(q7_out) == 5\nTrue",
         "failure_message": "output length should be 5",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> set(q7_out) <= set(['P', 'H'])\nTrue",
         "failure_message": "output contains answers other than P or H",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q7_out[0] == 'P' # Don't just copy the answer!\nTrue",
         "failure_message": "sub-question 1",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q7_out[1] == 'P' # Don't just copy the answer!\nTrue",
         "failure_message": "sub-question 2",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q7_out[2] == 'H' # Don't just copy the answer!\nTrue",
         "failure_message": "sub-question 3",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q7_out[3] == 'H' # Don't just copy the answer!\nTrue",
         "failure_message": "sub-question 4",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q7_out[4] == 'P' # Don't just copy the answer!\nTrue",
         "failure_message": "sub-question 5",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q8": {
     "name": "q8",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(q8_out) == 5\nTrue",
         "failure_message": "output length should be 5",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> set(q8_out) <= set(['MD', 'MCAR', 'MAR', 'NI'])\nTrue",
         "failure_message": "output contains answers other than the specified options",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q8_out[0] == 'NI'\nTrue",
         "failure_message": "sub-question 1: reviewers are more likely to review when dissatified",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q8_out[0] in ['NI', 'MCAR']\nTrue",
         "failure_message": "sub-question 1: partial; one column must be NI or MCAR",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q8_out[1] == 'MD'\nTrue",
         "failure_message": "sub-question 2: not the optimal answer",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q8_out[1] in ['MD', 'MAR']\nTrue",
         "failure_message": "sub-question 2: partial",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q8_out[2] == 'MAR'\nTrue",
         "failure_message": "sub-question 3: not the optimal answer",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q8_out[2] in ['NI', 'MAR']\nTrue",
         "failure_message": "sub-question 3: partial",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q8_out[3] in ['NI', 'MAR']\nTrue",
         "failure_message": "sub-question 4: not the optimal answer, how does having a serial number affect missingness?",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q8_out[3] in ['NI', 'MAR', 'MCAR']\nTrue",
         "failure_message": "sub-question 4: partial",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q8_out[4] == 'MAR'\nTrue",
         "failure_message": "sub-question 5: not the optimal answer",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q8_out[4] in ['MAR', 'NI', 'MCAR']\nTrue",
         "failure_message": "sub-question 5: partial",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q9": {
     "name": "q9",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(q9_out) == 5\nTrue",
         "failure_message": "output length should be 5",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> set(q9_out) <= set(['MD', 'MCAR', 'MAR', 'NI'])\nTrue",
         "failure_message": "output contains answers other than the specified options",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q9_out[0] == 'MAR'\nTrue",
         "failure_message": "sub-question 1",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q9_out[0] in ['MCAR', 'MAR', 'NI']\nTrue",
         "failure_message": "sub-question 1: partial",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q9_out[1] in ['MAR', 'NI']\nTrue",
         "failure_message": "sub-question 2",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q9_out[2] in ['MD', 'MAR']\nTrue",
         "failure_message": "sub-question 3",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q9_out[3] == 'NI'\nTrue",
         "failure_message": "sub-question 4",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q9_out[3] in ['NI', 'MCAR']\nTrue",
         "failure_message": "sub-question 4: partial",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q9_out[4] == 'MCAR'\nTrue",
         "failure_message": "sub-question 5",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q9_out[4] in ['MAR', 'NI', 'MCAR']\nTrue",
         "failure_message": "sub-question 5: partial",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
