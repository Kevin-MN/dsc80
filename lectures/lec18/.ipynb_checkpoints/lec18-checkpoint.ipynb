{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 18 – Text as Data\n",
    "\n",
    "## DSC 80, Spring 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Announcements\n",
    "\n",
    "- Lab 6 is due **today at 11:59PM**.\n",
    "    - **You don't have to do Question 3** ([even though it might work again](https://campuswire.com/c/G325FA25B/feed/1061)).\n",
    "- Project 3 is due on **Thursday, May 12th at 11:59PM**.\n",
    "- Look at the [Grade Report](https://www.gradescope.com/courses/379137/assignments/2051129/) on Gradescope, which summarizes your grades on all assessments so far.\n",
    "    - Project 2 and Lab 5 grades have also been released."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda\n",
    "\n",
    "- Example: Log parsing with regular expressions.\n",
    "- Quantifying text data.\n",
    "- Bag of words.\n",
    "\n",
    "Remember to refer to [dsc80.com/resources/#regular-expressions](https://dsc80.com/resources/#regular-expressions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Log parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Recall the **log string** from a few lectures ago."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "s = '''132.249.20.188 - - [05/May/2022:14:26:15 -0800] \"GET /my/home/ HTTP/1.1\" 200 2585'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use our new regex syntax (including capturing groups) to extract the day, month, year, and time from the log string `s`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = '\\[(.+)\\/(.+)\\/(.+):(.+):(.+):(.+) .+\\]'\n",
    "re.findall(exp, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "While above regex works, it is not very **specific**. It _works_ on incorrectly formatted log strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_s = '[adr/jduy/wffsdffs:r4s4:4wsgdfd:asdf 7]'\n",
    "re.findall(exp, other_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The more specific, the better!\n",
    "* Be as specific in your pattern matching as possible – you don't want to match and extract strings that don't fit the pattern you care about.\n",
    "    - `.*` matches every possible string, but we don't use it very often.\n",
    "    \n",
    "* A better date extraction regex:\n",
    "```\n",
    "\\[(\\d{2})\\/([A-Z]{1}[a-z]{2})\\/(\\d{4}):(\\d{2}):(\\d{2}):(\\d{2}) -\\d{4}\\]\n",
    "```\n",
    "\n",
    "    * `\\d{2}` matches any 2-digit number.\n",
    "    * `[A-Z]{1}` matches any single occurrence of any uppercase letter.\n",
    "    * `[a-z]{2}` matches any 2 consecutive occurrences of lowercase letters.\n",
    "    * Remember, special characters (`[`, `]`, `/`) need to be escaped with `\\`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_exp = '\\[(\\d{2})\\/([A-Z]{1}[a-z]{2})\\/(\\d{4}):(\\d{2}):(\\d{2}):(\\d{2}) -\\d{4}\\]'\n",
    "re.findall(new_exp, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A benefit of `new_exp` over `exp` is that it doesn't capture anything when the string doesn't follow the format we specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(new_exp, other_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Another character class\n",
    "\n",
    "The `\\b` character class refers to \"word boundaries\". It matches anything that separates letters/digits/underscores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall('\\\\b\\w+\\\\b', 'hello, my name is billy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall('\\\\b\\w+\\\\b', 'hello-my-name-is-bil_ly!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, the `\\w` character class refers to letters, digits, and underscores, i.e. \"word\" characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Question:** What's with the `\\\\`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aside: \"raw\" strings\n",
    "\n",
    "- Regular expressions use `\\` to escape special characters and to denote character classes (like `\\w` and `\\b`).\n",
    "- Python uses `\\` to demarcate special strings as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ho\\ney')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, the regex meaning and Python meaning of a special string clash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'hi\\billy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hi\\billy') # \\b means \"backspace\" in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hi\\\\billy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prevent Python from interpreting `\\b`, `\\n`, etc. as its own special strings, and to keep them in their \"raw\" form, use raw strings.\n",
    "\n",
    "To create a raw string, add the character `r` right before the quotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r'hi\\billy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r'hi\\billy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw strings can help us avoid misinterpretations like the one below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "re.findall('\\b\\w+\\b', 'hello, my name is billy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r'\\b\\w+\\b', 'hello, my name is billy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't want to use a raw string, you'd instead have to escape the `\\b` with another `\\`, as we did on the previous slide:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall('\\\\b\\w+\\\\b', 'hello, my name is billy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Limitations of regexes\n",
    "\n",
    "Writing a regular expression is like writing a program.\n",
    "* You need to know the syntax well.\n",
    "* They can be easier to write than to read.\n",
    "* They can be difficult to debug.\n",
    "\n",
    "Regular expressions are terrible at certain types of problems. Examples:\n",
    "* Anything involving counting (same number of instances of a and b).\n",
    "* Anything involving complex structure (palindromes).\n",
    "* Parsing highly complex text structure ([HTML](https://stackoverflow.com/questions/1732348/regex-match-open-tags-except-xhtml-self-contained-tags), for instance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Below is a regular expression that validates email addresses in Perl. See [this article](http://www.ex-parrot.com/~pdw/Mail-RFC822-Address.html) for more details.\n",
    "\n",
    "\n",
    "\n",
    "<center><img src=\"imgs/image_8.png\" width=700></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "StackOverflow crashed due to regex! See [this article](https://stackstatus.net/post/147710624694/outage-postmortem-july-20-2016) for the details.\n",
    "\n",
    "<center><img src='imgs/so_regex.png' width=60%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Advice\n",
    "\n",
    "- You don't need to force yourself to \"memorize\" regex syntax – refer to the resources in the [Agenda](#Agenda) section of the lecture and on the [Resources](https://dsc80.com/resources#regular-expressions) tab of the course website.\n",
    "- Also refer to the three tables of syntax in the lecture:\n",
    "    - [Regex building blocks](#Regex-building-blocks-🧱).\n",
    "    - [More regex syntax](#More-regex-syntax).\n",
    "    - [Even more regex syntax](#Even-more-regex-syntax).\n",
    "- **Note:** You don't always have to use regular expressions! If Python/`pandas` string methods work for your task, you can still use those.\n",
    "- **Play [Regex Golf](https://alf.nu/RegexGolf?world=regex&level=r00) to practice!** 🏌️\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quantifying text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Quantifying text data\n",
    "\n",
    "- How do we **quantify** the similarity of two text documents?\n",
    "- How do we use a text document as input in a regression or classification model?\n",
    "- **How do we turn a text document into a vector of numbers?**\n",
    "    - From 40A: A **design matrix** consists of one row per \"data point\", and one column per \"feature\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: San Diego employee salaries\n",
    "\n",
    "Recall, in Lectures 1 and 2, we worked with a dataset of San Diego city employee salaries in 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2021 data is now actually available, but we will use 2020 data as we did earlier in the quarter\n",
    "salaries = pd.read_csv('https://transcal.s3.amazonaws.com/public/export/san-diego-2020.csv')\n",
    "util.anonymize_names(salaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We asked the question, \"Does gender influence pay?\"\n",
    "\n",
    "A followup question to that was \"Do men and women make similar salaries amongst those with similar jobs?\" – but what makes two jobs similar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exploring job titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobtitles = salaries['Job Title']\n",
    "jobtitles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many job titles are there in the dataset? How many **unique** job titles are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobtitles.shape[0], jobtitles.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the most common job titles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobtitles.value_counts().iloc[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobtitles.value_counts().iloc[:25].sort_values().plot(kind='barh', figsize=(8, 6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Messiness of job titles\n",
    "\n",
    "- Are there multiple representations of the same job title (e.g. `'Assistant Fire Chief'` vs. `'Asst. Fire Chief'`?\n",
    "- Are there multiple representations of the same word that is used in multiple job titles (e.g. `'Civil Eng.'` vs `'Mechanical engineer'`)?\n",
    "\n",
    "Run the cell below repeatedly to get a feel for the \"messiness\" of job titles in their current state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobtitles.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Canonicalizing job titles\n",
    "\n",
    "Let's try to **canonicalize** job titles. To do this, we'll look at:\n",
    "\n",
    "- Punctuation.\n",
    "- \"Glue\" words.\n",
    "- Abbreviations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there job titles with unnecessary punctuation that we can remove? \n",
    "\n",
    "- To find out, we can write a regular expression that looks for characters other than letters, numbers, and spaces.\n",
    "\n",
    "- We can use regular expressions with the `.str` methods we learned earlier in the quarter just by using `regex=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobtitles.str.contains(r'[^A-Za-z0-9 ]', regex=True).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobtitles[jobtitles.str.contains(r'[^A-Za-z0-9 ]', regex=True)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like we should replace these pieces of punctuation with a single space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### \"Glue\" words\n",
    "\n",
    "Are there job titles with \"glue\" words in the middle, such as Assistant <u>to the</u> Chief?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To figure out if any titles contain the word `'to'`, we **can't** just do the following, because it will evaluate to `True` for job titles that have `'to'` anywhere in them, even if not as a standalone word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why are we converting to lowercase?\n",
    "jobtitles.str.lower().str.contains('to').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobtitles[jobtitles.str.lower().str.contains('to')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, we need to look for `'to'` separated by word boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobtitles.str.lower().str.contains(r'\\bto\\b', regex=True).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jobtitles[jobtitles.str.lower().str.contains(r'\\bto\\b', regex=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look for other filler words too, like `'the'` and `'for'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobtitles[jobtitles.str.lower().str.contains(r'\\bthe\\b', regex=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobtitles[jobtitles.str.lower().str.contains(r'\\bfor\\b', regex=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should probably remove these \"glue\" words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fixing punctuation and removing \"glue\" words\n",
    "\n",
    "To canonicalize job titles, we'll start by:\n",
    "- converting to lowercase,\n",
    "- removing each occurrence of `'to'`, `'the'`, and `'for'`,\n",
    "- replacing each non-letter/digit/space character with a space, and\n",
    "- replacing each sequence of multiple spaces with a single space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobtitles = (\n",
    "    jobtitles\n",
    "    .str.lower()\n",
    "    .str.replace(r'\\bto|\\bthe|\\bfor', '', regex=True)\n",
    "    .str.replace('[^A-Za-z0-9 ]', ' ', regex=True)\n",
    "    .str.replace(' +', ' ', regex=True)               # ' +' matches 1 or more occurrences of a space\n",
    "    .str.strip()                                      # Removes leading/trailing spaces if present\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobtitles.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Abbreviations \n",
    "\n",
    "Which job titles are inconsistently described? Let's look at three categories – librarians, engineers, and directors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobtitles[jobtitles.str.contains('libr')].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobtitles[jobtitles.str.contains('eng')].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobtitles[jobtitles.str.contains('dir')].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The limits of canonicalization\n",
    "\n",
    "- Our current approach requires a lot of manual labor.\n",
    "    - There may be more abbreviations in use amongst job titles (like `'asst'` for `'assistant'`), but how do we find them?\n",
    "- Remember, our goal is to quantify how similar two job titles are.\n",
    "- **Idea:** Two job titles are similar if they contain similar words (regardless of order)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bag of words 👜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A counts matrix\n",
    "\n",
    "Let's create a \"counts\" matrix, such that:\n",
    "- there is 1 row per job title,\n",
    "- there is 1 column per **unique** word that is used in job titles, and\n",
    "- the value in row `title` and column `word` is the number of occurrences of `word` in `title`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such a matrix might look like:\n",
    "\n",
    "| | senior | lecturer | teaching | professor | assistant | associate |\n",
    "| --- | --- | --- | --- | --- | --- | --- |\n",
    "| **senior lecturer** | 1 | 1 | 0 | 0 | 0 | 0 |\n",
    "| **assistant teaching professor** | 0 | 0 | 1 | 1 | 1 | 0 | \n",
    "| **associate professor** | 0 | 0 | 0 | 1 | 0 | 1 |\n",
    "| **senior assistant to the assistant professor** | 1 | 0 | 0 | 1 | 2 | 0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Creating a counts matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to determine all words that are used across all job titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jobtitles.str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = jobtitles.str.split().sum()\n",
    "all_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to find a list of all **unique** words used in titles. (We can do this with `np.unique`, but `value_counts` shows us the distribution, which is interesting.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = pd.Series(all_words).value_counts()\n",
    "unique_words.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unique_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the 435 unique words that are used in job titles, we can count the number of occurrences of the word in each job title.\n",
    "- `'assistant fire chief'` contains the word `'assistant'` once, the word `'fire'` once, and the word `'chief'` once.\n",
    "- `'assistant managers assistant'` contains the word `'assistant'` twice and the word `'managers'` once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created using a dictionary to avoid a \"DataFrame is highly fragmented\" warning.\n",
    "counts_dict = {}\n",
    "for word in unique_words.index:\n",
    "    re_pat = fr'\\b{word}\\b'\n",
    "    counts_dict[word] = jobtitles.str.count(re_pat).astype(int).tolist()\n",
    "    \n",
    "counts_df = pd.DataFrame(counts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`counts_df` has one row for all 12605 job titles (employees), and one column for each unique word that is used in a job title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To put into context what the numbers in `counts_df` mean, we can show the actual job title for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_df = pd.concat([jobtitles.to_frame(), counts_df], axis=1).set_index('Job Title')\n",
    "counts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first row tells us that the first job title contains `'police'` once and `'officer'` once. The fifth row tells us that the fifth job title contains `'fire'` once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Interpreting the counts matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Series below describes the 20 most common words used in job titles, along with the number of times they appeared in all job titles (including repeats). We will call these words \"top 20\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counts_df.iloc[:, :20].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Series below describes the **number of top 20 words** used in each job title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_df.iloc[:, :20].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Question: What job titles are most similar to `'asst fire chief'`?\n",
    "\n",
    "- Remember, our idea was to treat two job titles as similar if they contain similar words (regardless of order).\n",
    "- Now that we have `counts_df`, we have a (row) vector for each job title.\n",
    "- **How do we measure how similar two vectors are?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, let's compare `'asst fire chief'` to `'fire battalion chief'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "afc = counts_df.loc['asst fire chief'].iloc[0]\n",
    "afc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbc = counts_df.loc['fire battalion chief'].iloc[0]\n",
    "fbc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can stack these two vectors horizontally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_counts = (\n",
    "    pd.concat([afc, fbc], axis=1)\n",
    "    .sort_values(by=['asst fire chief', 'fire battalion chief'], ascending=False)\n",
    "    .head(10)\n",
    "    .T\n",
    ")\n",
    "\n",
    "pair_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "One way to measure how similar the above two vectors are is through their **dot product**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(pair_counts.iloc[0] * pair_counts.iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, since both vectors consist only of 1s and 0s, the dot product is equal to the **number of shared words** between the two job titles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aside: dot product\n",
    "\n",
    "- Recall, if $\\vec{a} = \\begin{bmatrix} a_1 & a_2 & ... & a_n \\end{bmatrix}^T$ and $\\vec{b} = \\begin{bmatrix} b_1 & b_2 & ... & b_n \\end{bmatrix}^T$ are two vectors, then their **dot product** $\\vec{a} \\cdot \\vec{b}$ is defined as:\n",
    "\n",
    "$$\\vec{a} \\cdot \\vec{b} = a_1b_1 + a_2b_2 + ... + a_nb_n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The dot product also has a **geometric** interpretation. If $|\\vec{a}|$ and $|\\vec{b}|$ are the $L_2$ norms (lengths) of $\\vec{a}$ and $\\vec{b}$, and $\\theta$ is the angle between $\\vec{a}$ and $\\vec{b}$, then:\n",
    "\n",
    "$$\\vec{a} \\cdot \\vec{b} = |\\vec{a}| |\\vec{b}| \\cos \\theta$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- $\\cos \\theta$ is equal to its maximum value (1) when $\\theta = 0$, i.e. when $\\vec{a}$ and $\\vec{b}$ point in the same direction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- 🚨 **Key idea: The more similar two vectors are, the larger their dot product is!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Computing similarities\n",
    "\n",
    "To find the job title that is most similar to `'asst fire chief'`, we can compute the dot product of the `'asst fire chief'` word vector with all other titles' word vectors, and find the title with the highest dot product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do so, we can apply `np.dot` to each row that doesn't correspond to `'asst fire chief'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dots = (\n",
    "    counts_df[counts_df.index != 'asst fire chief']\n",
    "    .apply(lambda s: np.dot(s, afc), axis=1)\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "dots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unique job titles that are **most similar** to `'asst fire chief'` are given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(dots.index[dots == dots.max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that they all share two words in common with `'asst fire chief'`.\n",
    "\n",
    "**Note:** To truly use the dot product as a measure of similarity, we should **normalize** by the lengths of the word vectors. More on this soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bag of words\n",
    "\n",
    "- The **bag of words** model represents texts (e.g. job titles, sentences, documents) as **vectors of word counts**.\n",
    "    - The \"counts\" matrices we have worked with so far were created using the bag of words model.\n",
    "    - The bag of words model defines a **vector space** in $\\mathbb{R}^{\\text{number of unique words}}$.\n",
    "- It is called \"bag of words\" because it doesn't consider **order**.\n",
    "\n",
    "<center><img src='imgs/bag-of-words.jpeg' width=45%></center>\n",
    "\n",
    "<center><a href=\"https://42f6861cgkip12ijm63i3orf-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/2020-07-bagofwords.jpg\">(source)</a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cosine similarity and bag of words\n",
    "\n",
    "To measure the similarity between two word vectors, we compute their dot product, also known as their **cosine similarity**.\n",
    "\n",
    "$$\\cos \\theta = \\frac{\\vec{a} \\cdot \\vec{b}}{|\\vec{a}| | \\vec{b}|}$$\n",
    "\n",
    "If $\\cos \\theta$ is large, the two word vectors are similar. **It is important to normalize by the lengths of the vectors**, otherwise texts with more words will have artificially high similarities with other texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Note:** Sometimes, you will see the **cosine distance** being used. It is the complement of cosine similarity:\n",
    "  \n",
    "  $$\\text{dist}(\\vec{a}, \\vec{b}) = 1 - \\cos \\theta$$\n",
    "  \n",
    "If $\\text{dist}(\\vec{a}, \\vec{b})$ is small, the two word vectors are similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A recipe for computing similarities\n",
    "\n",
    "Given a set of texts, to find the **most similar** text to one text $T$ in particular:\n",
    "- Use the bag of words model to create a counts matrix. Specifically:\n",
    "    - Create an index out of **all** distinct words used across all texts.\n",
    "    - Create a single vector for each text by counting the number of occurrences of each distinct word.\n",
    "- Compute the cosine similarity between text $T$ and all other texts.\n",
    "- The other text with the greatest cosine similarity is the most similar, under the bag of words model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Global warming 🌎\n",
    "\n",
    "Consider the following **sentences**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = pd.Series([\n",
    "    'I really want global peace',\n",
    "    'I must love global warming',\n",
    "    'We must solve climate change'\n",
    "])\n",
    "\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's represent each sentence using the bag of words model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = pd.Series(sentences.str.split().sum()).value_counts()\n",
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_dict = {}\n",
    "for word in unique_words.index:\n",
    "    re_pat = fr'\\b{word}\\b'\n",
    "    counts_dict[word] = sentences.str.count(re_pat).astype(int).tolist()\n",
    "    \n",
    "counts_df = pd.DataFrame(counts_dict).set_index(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's now find the cosine similarity between each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is an easier way of doing this in sklearn, as we will see soon\n",
    "def sim_pair(s1, s2):\n",
    "    return np.dot(s1, s2) / (np.linalg.norm(s1) * np.linalg.norm(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_pair(counts_df.iloc[0], counts_df.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_pair(counts_df.iloc[0], counts_df.iloc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_pair(counts_df.iloc[1], counts_df.iloc[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Issue:** Bag of words only encodes the **words** that each sentence uses, not their **meanings**.\n",
    "- Sentence 0 and sentence 2 have similar meanings, but have no shared words.\n",
    "- Sentence 0 and sentence 1 have very different meanings, but a relatively high cosine similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pitfalls of the bag of words model\n",
    "\n",
    "Remember, the key assumption underlying the bag of words model is that **two texts are similar if they share many words in common**.\n",
    "\n",
    "- The bag of words model doesn't consider **order**.\n",
    "    - The job titles `'asst fire chief'` and `'chief fire asst'` are treated as the same.\n",
    "- The bag of words model treats all words as being equally important.\n",
    "    - `'asst'` and `'fire'` have the same importance, even though `'fire'` is probably more important in describing someone's job title.\n",
    "- The bag of words model doesn't consider the **meaning** of words.\n",
    "    - `'I love data science'` and `'I hate data science'` share 75% of their words, but have very different meanings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary, next time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "- `pandas` `.str` methods can use regular expressions; just set `regex=True`.\n",
    "- Canonicalization can be difficult in practice when working with large datasets.\n",
    "- The bag of words model allows us to turn texts into numerical vectors of word counts.\n",
    "    - It treats two texts as similar if they share many words in common.\n",
    "    - It doesn't consider the order, importance, or meaning of words.\n",
    "- **Next time:** An improvement to bag of words."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "livereveal": {
   "scroll": true,
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
