{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import YouTubeVideo, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 19 ‚Äì Text as Data, Continued\n",
    "\n",
    "## DSC 80, Spring 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Announcements\n",
    "\n",
    "- Discussion 6 (text data) is tonight.\n",
    "    - It will be helpful for Project 4 (out this weekend).\n",
    "- Project 3 is due on **Thursday, May 12th at 11:59PM**.\n",
    "- Lab 7 is due on **Monday, May 16th at 11:59PM**.\n",
    "- Look at the [Grade Report](https://www.gradescope.com/courses/379137/assignments/2051129/) on Gradescope, which summarizes your grades on all assessments so far.\n",
    "    - Project 2 and Lab 5 grades have also been released.\n",
    "- üì£ Come to the DSC **Town Hall**, where you can voice your feedback about the DSC program to faculty. \n",
    "    - Tuesday, May 16th from 3-5PM in the SDSC Auditorium.\n",
    "    - [RSVP by **noon on Friday** to secure **free pizza üçï**!](https://docs.google.com/forms/d/e/1FAIpQLScfP_EFEYt1d5N7dWXGQqQaOik3nY_KTIMYuB1uuEgjH83vRw/viewform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda\n",
    "\n",
    "- Bag of words üí∞.\n",
    "- TF-IDF.\n",
    "- Example: State of the Union addresses üé§."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bag of words üí∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "salaries = pd.read_csv('https://transcal.s3.amazonaws.com/public/export/san-diego-2020.csv')\n",
    "jobtitles = salaries['Job Title']\n",
    "\n",
    "jobtitles = (\n",
    "    jobtitles\n",
    "    .str.lower()\n",
    "    .str.replace(r'\\bto|\\bthe|\\bfor', '', regex=True)\n",
    "    .str.replace('[^A-Za-z0-9 ]', ' ', regex=True)\n",
    "    .str.replace(' +', ' ', regex=True)               \n",
    "    .str.strip()                                      \n",
    ")\n",
    "\n",
    "all_words = jobtitles.str.split().sum()\n",
    "unique_words = pd.Series(all_words).value_counts()\n",
    "\n",
    "counts_dict = {}\n",
    "for word in unique_words.index:\n",
    "    re_pat = fr'\\b{word}\\b'\n",
    "    counts_dict[word] = jobtitles.str.count(re_pat).astype(int).tolist()\n",
    "    \n",
    "counts_df = pd.DataFrame(counts_dict).set_index(jobtitles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recap\n",
    "\n",
    "Recall, last class we created a **counts matrix** out of a Series containing San Diego employees' job titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobtitles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Question: What job titles are most similar to `'asst fire chief'`?\n",
    "\n",
    "- Remember, our idea was to treat two job titles as similar if they contain similar words (regardless of order).\n",
    "- Now that we have `counts_df`, we have a (row) vector for each job title.\n",
    "- **How do we measure how similar two vectors are?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, let's compare `'asst fire chief'` to `'fire battalion chief'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "afc = counts_df.loc['asst fire chief'].iloc[0]\n",
    "afc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbc = counts_df.loc['fire battalion chief'].iloc[0]\n",
    "fbc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can stack these two vectors horizontally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_counts = (\n",
    "    pd.concat([afc, fbc], axis=1)\n",
    "    .sort_values(by=['asst fire chief', 'fire battalion chief'], ascending=False)\n",
    "    .head(10)\n",
    "    .T\n",
    ")\n",
    "\n",
    "pair_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "One way to measure how similar the above two vectors are is through their **dot product**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(pair_counts.iloc[0] * pair_counts.iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, since both vectors consist only of 1s and 0s, the dot product is equal to the **number of shared words** between the two job titles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aside: dot product\n",
    "\n",
    "- Recall, if $\\vec{a} = \\begin{bmatrix} a_1 & a_2 & ... & a_n \\end{bmatrix}^T$ and $\\vec{b} = \\begin{bmatrix} b_1 & b_2 & ... & b_n \\end{bmatrix}^T$ are two vectors, then their **dot product** $\\vec{a} \\cdot \\vec{b}$ is defined as:\n",
    "\n",
    "$$\\vec{a} \\cdot \\vec{b} = a_1b_1 + a_2b_2 + ... + a_nb_n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The dot product also has a **geometric** interpretation. If $|\\vec{a}|$ and $|\\vec{b}|$ are the $L_2$ norms (lengths) of $\\vec{a}$ and $\\vec{b}$, and $\\theta$ is the angle between $\\vec{a}$ and $\\vec{b}$, then:\n",
    "\n",
    "$$\\vec{a} \\cdot \\vec{b} = |\\vec{a}| |\\vec{b}| \\cos \\theta$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- $\\cos \\theta$ is equal to its maximum value (1) when $\\theta = 0$, i.e. when $\\vec{a}$ and $\\vec{b}$ point in the same direction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- üö® **Key idea: The more similar two vectors are, the larger their dot product is!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Computing similarities\n",
    "\n",
    "To find the job title that is most similar to `'asst fire chief'`, we can compute the dot product of the `'asst fire chief'` word vector with all other titles' word vectors, and find the title with the highest dot product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do so, we can apply `np.dot` to each row that doesn't correspond to `'asst fire chief'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dots = (\n",
    "    counts_df[counts_df.index != 'asst fire chief']\n",
    "    .apply(lambda s: np.dot(s, afc), axis=1)\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "dots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unique job titles that are **most similar** to `'asst fire chief'` are given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(dots.index[dots == dots.max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that they all share two words in common with `'asst fire chief'`.\n",
    "\n",
    "**Note:** To truly use the dot product as a measure of similarity, we should **normalize** by the lengths of the word vectors. More on this soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bag of words\n",
    "\n",
    "- The **bag of words** model represents documents (e.g. job titles, sentences, essays) as **vectors of word counts**.\n",
    "    - The \"counts\" matrices we have worked with so far were created using the bag of words model.\n",
    "    - The bag of words model defines a **vector space** in $\\mathbb{R}^{\\text{number of unique words}}$.\n",
    "- It is called \"bag of words\" because it doesn't consider **order**.\n",
    "\n",
    "<center><img src='imgs/bag-of-words.jpeg' width=45%></center>\n",
    "\n",
    "<center><a href=\"https://42f6861cgkip12ijm63i3orf-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/2020-07-bagofwords.jpg\">(source)</a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cosine similarity and bag of words\n",
    "\n",
    "To measure the similarity between two word vectors, we compute their **cosine similarity**.\n",
    "\n",
    "$$\\cos \\theta = \\frac{\\vec{a} \\cdot \\vec{b}}{|\\vec{a}| | \\vec{b}|}$$\n",
    "\n",
    "If $\\cos \\theta$ is large, the two word vectors are similar. **It is important to normalize by the lengths of the vectors**, otherwise documents with more words will have artificially high similarities with other documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Note:** Sometimes, you will see the **cosine distance** being used. It is the complement of cosine similarity:\n",
    "  \n",
    "  $$\\text{dist}(\\vec{a}, \\vec{b}) = 1 - \\cos \\theta$$\n",
    "  \n",
    "If $\\text{dist}(\\vec{a}, \\vec{b})$ is small, the two word vectors are similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A recipe for computing similarities\n",
    "\n",
    "Given a set of documents, to find the **most similar** document to one document $D$ in particular:\n",
    "- Use the bag of words model to create a counts matrix. Specifically:\n",
    "    - Create an index out of **all** distinct words used across all documents.\n",
    "    - Create a single vector for each document by counting the number of occurrences of each distinct word.\n",
    "- Compute the cosine similarity between document $D$ and all other texts.\n",
    "- The other document with the greatest cosine similarity is the most similar, under the bag of words model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Global warming üåé\n",
    "\n",
    "Consider the following **sentences** (each of which is a \"document\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = pd.Series([\n",
    "    'I really want global peace',\n",
    "    'I must love love global warming',\n",
    "    'I must solve climate change'\n",
    "])\n",
    "\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's represent each sentence using the bag of words model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = pd.Series(sentences.str.split().sum()).value_counts()\n",
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_dict = {}\n",
    "for word in unique_words.index:\n",
    "    re_pat = fr'\\b{word}\\b'\n",
    "    counts_dict[word] = sentences.str.count(re_pat).astype(int).tolist()\n",
    "    \n",
    "counts_df = pd.DataFrame(counts_dict).set_index(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's now find the cosine similarity between each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is an easier way of doing this in sklearn, as we will see soon\n",
    "def sim_pair(s1, s2):\n",
    "    return np.dot(s1, s2) / (np.linalg.norm(s1) * np.linalg.norm(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_pair(counts_df.iloc[0], counts_df.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_pair(counts_df.iloc[0], counts_df.iloc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_pair(counts_df.iloc[1], counts_df.iloc[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Issue:** Bag of words only encodes the **words** that each sentence uses, not their **meanings**.\n",
    "- To us, the most similar sentences are sentences 0 and 2 (both are positive statements about improving the world), however that pair has the lowest cosine similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pitfalls of the bag of words model\n",
    "\n",
    "Remember, the key assumption underlying the bag of words model is that **two documents are similar if they share many words in common**.\n",
    "\n",
    "- The bag of words model doesn't consider **order**.\n",
    "    - The job titles `'asst fire chief'` and `'chief fire asst'` are treated as the same.\n",
    "- The bag of words model treats all words as being equally important.\n",
    "    - `'asst'` and `'fire'` have the same importance, even though `'fire'` is probably more important in describing someone's job title.\n",
    "- The bag of words model doesn't consider the **meaning** of words.\n",
    "    - `'I love data science'` and `'I hate data science'` share 75% of their words, but have very different meanings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The importance of words\n",
    "\n",
    "**Issue:** The bag of words model doesn't know which words are \"important\" in a document. How do we determine which words are important?\n",
    "- The most common words (\"the\", \"of\") often **don't** have much meaning!\n",
    "- The very rare words are also less important!\n",
    "\n",
    "**Goal:** Find a way of quantifying the importance of a word in a document by **balancing the above two factors**.\n",
    "- Put another way: find the word that **best summarizes** a document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Term frequency\n",
    "\n",
    "- The **term frequency** of a word (term) $t$ in a document $d$, denoted $\\text{tf}(t, d)$ is the proportion of words in document $d$ that are equal to $t$.\n",
    "\n",
    "$$\\text{tf}(t, d) = \\frac{\\text{number of occurrences of $t$ in $d$}}{\\text{total number of words in $d$}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Example:** What is the term frequency of \"billy\" in the following document?\n",
    "\n",
    "<center>\"my brother has a friend named <b>billy</b> who has an uncle named <b>billy</b>\"</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Answer:** $\\frac{2}{13}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Intuition: Words that occur often within a document are important to the document's meaning.\n",
    "    - If $\\text{tf}(t, d)$ is large, then word $t$ occurs often in $d$.\n",
    "    - If $\\text{tf}(t, d)$ is small, then word $t$ does not occur often $d$.\n",
    "- Issue: \"has\" also has a TF of $\\frac{2}{13}$, but it seems less important than \"billy\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inverse document frequency\n",
    "\n",
    "- The **inverse document frequency** of a word $t$ in a set of documents $d_1, d_2, ...$ is\n",
    "\n",
    "$$\\text{idf}(t) = \\log \\left(\\frac{\\text{total number of documents}}{\\text{number of documents in which $t$ appears}} \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Example:** What is the inverse document frequency of \"billy\" in the following three documents?\n",
    "    - \"my brother has a friend named **billy** who has an uncle named **billy**\"\n",
    "    - \"my favorite artist is named jilly boel\"\n",
    "    - \"why does he talk about someone named **billy** so often\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Answer:** $\\log \\left(\\frac{3}{2}\\right) \\approx 0.4055$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Intuition: If a word appears in every document (like \"the\" or \"of\"), it is probably not a good summary of any one document.\n",
    "    - If $\\text{tdf}(t)$ is large, then $t$ is rarely found in documents.\n",
    "    - If $\\text{tdf}(t)$ is small, then $t$ is commonly found in documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Intuition\n",
    "\n",
    "$$\\text{tf}(t, d) = \\frac{\\text{number of occurrences of $t$ in $d$}}{\\text{total number of words in $d$}}$$\n",
    "\n",
    "$$\\text{idf}(t) = \\log \\left(\\frac{\\text{total number of documents}}{\\text{number of documents in which $t$ appears}} \\right)$$\n",
    "\n",
    "**Goal:** Quantify how well word $t$ **summarizes** document $d$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If $\\text{tf}(t, d)$ is small, then $t$ doesn't occur very often in $d$, so $t$ can't be a good summary of $d$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If $\\text{idf}(t)$ is small, then $t$ occurs often amongst all documents, and so it is not a good summary of any one document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If $\\text{tf}(t, d)$ and $\\text{idf}(t)$ are both large, then **$t$ occurs often in $d$ but rarely overall**.\n",
    "    - In such a case, $t$ is **a good summary** of document $d$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Term frequency-inverse document frequency\n",
    "\n",
    "The **term frequency-inverse document frequency (TF-IDF)** of word $t$ in document $d$ is the product:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\\text{tfidf}(t, d) &= \\text{tf}(t, d) \\cdot \\text{idf}(t) \\\\\\ &= \\frac{\\text{number of occurrences of $t$ in $d$}}{\\text{total number of words in $d$}} \\cdot \\log \\left(\\frac{\\text{total number of documents}}{\\text{number of documents in which $t$ appears}} \\right) \\end{align*} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If $\\text{tfidf}(t, d)$ is large, then $t$ is a good summary of $d$.\n",
    "    - But to know if $\\text{tfidf}(t, d)$ is large, we need to compare it to $\\text{tfidf}(t_i, d)$, for several different words $t_i$.\n",
    "\n",
    "- TF-IDF is a **heuristic** ‚Äì it has no probabilistic justification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Computing TF-IDF\n",
    "\n",
    "**Question:** What is the TF-IDF of \"global\" in the second sentence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = sentences.iloc[1].count('global') / len(sentences.iloc[1].split())\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idf = np.log(len(sentences) / sentences.str.contains('global').sum())\n",
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf * idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Question:** Is this big or small? Is \"global\" the **best** summary of the second sentence?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### TF-IDF of all words in all documents\n",
    "\n",
    "On its own, the TF-IDF of a word in a document doesn't really tell us anything; we must compare it to TF-IDFs of other words in that same document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = np.unique(sentences.str.split().sum())\n",
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_dict = {}\n",
    "\n",
    "for word in unique_words:\n",
    "    re_pat = fr'\\b{word}\\b'\n",
    "    tf = sentences.str.count(re_pat) / sentences.str.split().str.len()\n",
    "    idf = np.log(len(sentences) / sentences.str.contains(re_pat).sum())\n",
    "    tfidf_dict[word] = tf * idf\n",
    "    \n",
    "tfidf = pd.DataFrame(tfidf_dict).set_index(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The above DataFrame tells us that:\n",
    "- the TF-IDF of `'peace'` in the first sentence is 0.219722,\n",
    "- the TF-IDF of `'climate'` in the second sentence is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that there are two ways that $\\text{tfidf}(t, d)$ can be 0:\n",
    "- Word $t$ appears in every document (then $\\text{idf}(t) = \\log (1) = 0$).\n",
    "- Word $t$ does not appear in document $d$ (then $\\text{tf}(t, d) = \\frac{0}{\\text{len}(d)} = 0$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The word that **best summarizes** a document is the word with the highest TF-IDF for that document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look closely at the rows of `tfidf` ‚Äì in sentences 0 and 2, the max TF-IDF is not unique!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: State of the Union addresses üé§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('mVIXLQrC9rE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sotu = open('data/stateoftheunion1790-2022.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sotu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entire **corpus** (another word for \"set of documents\") is over 10 million characters long... let's not display it in our notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(sotu[:20000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each speech is separated by `'***'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches = sotu.split('\\n***\\n')[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(speeches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that each \"speech\" currently contains other information, like the name of the president and the date of the address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(speeches[-1][:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's extract just the speech text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_struct(speech):\n",
    "    L = speech.strip().split('\\n', maxsplit=3)\n",
    "    L[3] = re.sub(r\"[^A-Za-z' ]\", ' ', L[3]).lower()\n",
    "    return dict(zip(['speech', 'president', 'date', 'contents'], L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches_df = pd.DataFrame(list(map(extract_struct, speeches)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Finding the most important words in each speech\n",
    "\n",
    "Here, a \"document\" is a speech. We have 232 documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A rough sketch of what we'll compute:\n",
    "\n",
    "```\n",
    "for each word w:\n",
    "    for each speech d:\n",
    "        compute tfidf(w, d)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = pd.Series(speeches_df['contents'].str.split().sum()).value_counts()\n",
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = unique_words.iloc[:500].index\n",
    "\n",
    "tfidf_dict = {}\n",
    "tf_denom = speeches_df['contents'].str.split().str.len()\n",
    "for word in unique_words:\n",
    "    re_pat = fr' {word} ' # Imperfect pattern for speed\n",
    "    tf = speeches_df['contents'].str.count(re_pat) / tf_denom\n",
    "    idf = np.log(len(speeches_df) / speeches_df['contents'].str.contains(re_pat).sum())\n",
    "    tfidf_dict[word] =  tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = pd.DataFrame(tfidf_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the TF-IDFs of many common words are all 0!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summarizing speeches\n",
    "\n",
    "By using `idxmax`, we can find the word with the highest TF-IDF in each speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = tfidf.idxmax(axis=1)\n",
    "summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to see the 5 words with the highest TF-IDFs, for each speech?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_largest(row):\n",
    "    return list(row.index[row.argsort()][-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = tfidf.apply(five_largest, axis=1)\n",
    "keywords_df = pd.concat([\n",
    "    speeches_df['president'],\n",
    "    speeches_df['date'],\n",
    "    keywords\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to see every single row of `keywords_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', 300):\n",
    "    display(keywords_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aside: What if we remove the $\\log$ from $\\text{idf}(t)$?\n",
    "\n",
    "Let's try it and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_nl_dict = {}\n",
    "tf_denom = speeches_df['contents'].str.split().str.len()\n",
    "for word in unique_words:\n",
    "    re_pat = fr' {word} ' # Imperfect pattern for speed\n",
    "    tf = speeches_df['contents'].str.count(re_pat) / tf_denom\n",
    "    idf_nl = len(speeches_df) / speeches_df['contents'].str.contains(re_pat).sum()\n",
    "    tfidf_nl_dict[word] =  tf * idf_nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_nl = pd.DataFrame(tfidf_nl_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_nl = tfidf_nl.apply(five_largest, axis=1)\n",
    "keywords_nl_df = pd.concat([\n",
    "    speeches_df['president'],\n",
    "    speeches_df['date'],\n",
    "    keywords_nl\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_nl_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The role of $\\log$ in $\\text{idf}(t)$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\\text{tfidf}(t, d) &= \\text{tf}(t, d) \\cdot \\text{idf}(t) \\\\\\ &= \\frac{\\text{number of occurrences of $t$ in $d$}}{\\text{total number of words in $d$}} \\cdot \\log \\left(\\frac{\\text{total number of documents}}{\\text{number of documents in which $t$ appears}} \\right) \\end{align*} $$\n",
    "\n",
    "- Remember, for any positive input $x$, $\\log(x)$ is (much) smaller than $x$.\n",
    "- In $\\text{idf}(t)$, the $\\log$ \"dampens\" the impact of the ratio $\\frac{\\text{# documents}}{\\text{# documents with $t$}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If a word is very common, the ratio will be close to 1. The log of the ratio will be close to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1000 / 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(1000 / 999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If a word is very rare, the ratio will be very large. However, for instance, a word being seen in **2 out of 50** documents is not very different than being seen in **2 out of 500** documents (it is very rare in both cases), and so $\\text{idf}(t)$ should be similar in both cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(50 / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(500 / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(50 / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(500 / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary, next time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "- The bag of words model allows us to turn documents into numerical vectors of word counts.\n",
    "    - It treats two documents as similar if they share many words in common.\n",
    "    - It doesn't consider the order, importance, or meaning of words.\n",
    "- Term frequency-inverse document frequency (TF-IDF) is a statistic that tries to quantify how **important** a word (term) is to a document. It balances:\n",
    "    - **how often a word appears in a particular document**, $\\text{tf}(t, d)$, with\n",
    "    - **how often a word appears across documents**, $\\text{idf}(t)$.\n",
    "- For a given document, the word with the highest TF-IDF best summarizes that document.\n",
    "- **Next time:** Modeling and features."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "livereveal": {
   "scroll": true,
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
