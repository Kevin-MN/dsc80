{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 9 ‚Äì Combining Data\n",
    "\n",
    "## DSC 80, Spring 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Announcements\n",
    "\n",
    "- Discussion 3 is due (for extra credit!) **tomorrow at 11:59PM**.\n",
    "- Lab 3 is due on **Monday, April 18th 11:59PM**.\n",
    "    - Check [here](https://campuswire.com/c/G325FA25B/feed/507) for clarifications.\n",
    "- Lab 1 (+more) grades are released ‚Äì see [this post](https://campuswire.com/c/G325FA25B/feed/509) for details, and [this post](https://campuswire.com/c/G325FA25B/feed/508) for assignment solutions.\n",
    "- Watch [this video üé•](https://www.youtube.com/watch?v=uUawZfAgA64) for tips on how to work with the command-line.\n",
    "- Project 2 will be released this weekend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda\n",
    "\n",
    "- Concatenating vertically.\n",
    "- Concatenating horizontally.\n",
    "- Joining and merging.\n",
    "- Working with time series data.\n",
    "\n",
    "Good resource: `pandas` [User Guide](https://pandas.pydata.org/docs/user_guide/merging.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap: Concatenating vertically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Grades\n",
    "\n",
    "By default, `pd.concat` stacks DataFrames row-wise, i.e. on top of one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_A = pd.DataFrame({\n",
    "    'Name': ['Annie', 'Billy', 'Sally', 'Tommy'],\n",
    "    'Midterm': [98, 82, 23, 45],\n",
    "    'Final': [88, 100, 99, 67]\n",
    "})\n",
    "\n",
    "section_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_B = pd.DataFrame({\n",
    "    'Name': ['Junior', 'Rex', 'Flash'],\n",
    "    'Midterm': [70, 99, 81],\n",
    "    'Final': [42, 25, 90]\n",
    "})\n",
    "\n",
    "section_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use `pd.concat` on a list of the above two DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([section_A, section_B])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ‚ö†Ô∏è Warning: No loops!\n",
    "\n",
    "- `pd.concat` returns a copy; it does not modify any of the input DataFrames.\n",
    "- Do **not** use `pd.concat` in a loop, as it has terrible time and space efficiency.\n",
    "\n",
    "```py\n",
    "total = pd.DataFrame()\n",
    "for df in dataframes:\n",
    "    total = total.concat(df)\n",
    "```\n",
    "\n",
    "- Instead, use `pd.concat(dataframes)`, where `dataframes` is a list of DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Concatenating horizontally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Grades (again)\n",
    "\n",
    "Suppose we have two DataFrames, `exams` and `assignments`, which both contain different attributes for the same individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exams = section_A.copy()\n",
    "exams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignments = exams[['Name']].assign(Homeworks=[99, 45, 23, 81],\n",
    "                                     Labs=[100, 100, 99, 100])\n",
    "\n",
    "assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try to combine these DataFrames with `pd.concat`, we don't quite get what we're looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([exams, assignments])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But that's where the `axis` argument becomes handy. \n",
    "\n",
    "Remember, most `pandas` operations default to `axis=0`, but here we want to concatenate the columns of `exams` to the columns of `assignments`, so we should use `axis=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([exams, assignments], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `'Name'` column appears twice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Concatenating horizontally\n",
    "\n",
    "- To concatenate two DataFrames horizontally, use `pd.concat` with `axis=1`.\n",
    "- Concatenation is done by matching indexes, regardless of their order. **It does not look at any column values!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src='imgs/merging_concat_series_ignore_index.png' width='80%'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Note that the call to `pd.concat` below works as expected, even though the orders of the names in `exams_by_name` and `assignments_by_name` are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# .loc[::-1] reverses the rows of the DataFrame\n",
    "exams_by_name = exams.set_index('Name').loc[::-1]\n",
    "exams_by_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignments_by_name = assignments.set_index('Name')\n",
    "assignments_by_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([exams_by_name, assignments_by_name], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Remember that `pd.concat` only looks at the index when combining rows, not at any other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exams_reversed = exams.loc[::-1].reset_index(drop=True)\n",
    "exams_reversed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([exams_reversed, assignments], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Missing rows?\n",
    "\n",
    "If we concatenate two DataFrames that don't share row indexes, `NaN`s are added in the rows that aren't shared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exams_extra = exams.copy()\n",
    "exams_extra.loc[4] = ['Junior', 100, 100]\n",
    "exams_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([exams_extra, assignments], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary: `pd.concat`\n",
    "\n",
    "- `pd.concat` \"stitches\" two or more DataFrames together.\n",
    "- If you use `axis=0`, the DataFrames are concatenated **vertically** based on column names (rows on top of rows).\n",
    "- If you use `axis=1`, the DataFrames are concatenated **horizontally** based on row indexes (columns next to columns)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Joining and merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Concatenating horizontally\n",
    "\n",
    "- `pd.concat` with `axis=1` combines DataFrames horizontally.\n",
    "- To combine DataFrames horizontally in more advanced ways, we perform a **join** (also known as a **merge**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Joins\n",
    "\n",
    "- A **join** creates a new DataFrame by combining the rows of two DataFrames.\n",
    "- A join is appropriate when we have two sources of information\n",
    "    - about the same individuals, that is\n",
    "    - linked by a common column.\n",
    "- The common column is called the **join key**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example\n",
    "\n",
    "Here, the join key is `'Player Id'`.\n",
    "\n",
    "<center><img src=\"imgs/join.png\" width=\"50%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The `merge` method\n",
    "\n",
    "- The `merge` DataFrame method joins two tables by columns or indexes.\n",
    "    - \"Merge\" is just `pandas`' word for \"join\".\n",
    "    - It also exists as a `pandas` function.\n",
    "- If join keys are not specified, all shared columns between the two DataFrames are used by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's work with a small example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps = pd.DataFrame({\n",
    "    'City': ['San Diego', 'Toronto', 'Rome'],\n",
    "    'Temperature': [76, 28, 56]\n",
    "})\n",
    "\n",
    "temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = pd.DataFrame({\n",
    "    'City': ['Toronto', 'Shanghai', 'San Diego'],\n",
    "    'Country': ['Canada', 'China', 'USA']\n",
    "})\n",
    "\n",
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps.merge(countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We didn't specify which columns to merge on, so it defaulted to `'City'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Join types: inner joins\n",
    "\n",
    "- Note that `'Rome'` and `'Shanghai'` do not appear in the merged DataFrame.\n",
    "- This is because there is:\n",
    "    - no city named `'Rome'` in the second DataFrame, and\n",
    "    - no city named `'Shanghai'` in the first DataFrame.\n",
    "- The default type of join that `merge` performs is an **inner join**, which keeps the **intersection** of the join keys.\n",
    "\n",
    "\n",
    "<center><img src='imgs/image_0.png' width=40%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Different join types handle mismatches differently\n",
    "\n",
    "There are four types of joins.\n",
    "\n",
    "* **Inner:** keep **only** matching keys (intersection).\n",
    "* **Outer:** keeps **all** keys in both DataFrames (union).\n",
    "* **Left:** keep all keys in the left DataFrame, whether or not they are in the right DataFrame.\n",
    "* **Right:** keep all keys in the right DataFrame, whether or not they are in the left DataFrame.\n",
    "\n",
    "<center><img src='imgs/image_1.png' width=60%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Examples of join types\n",
    "\n",
    "- To specify which type of join we want to perform, we use the `how` argument (the default is `how='inner'`).\n",
    "- The left DataFrame is the DataFrame that **preceeds** `.merge`, and the right DataFrame is the argument to `merge`.\n",
    "- Alternatively, you can use the `pd.merge` **function**, in which the first argument is the left DataFrame and the second argument is the right DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try an outer join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps.merge(countries, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge is also a pandas function\n",
    "pd.merge(temps, countries, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the `NaN`s in the rows for `'Rome'` and `'Shanghai'`.\n",
    "\n",
    "Also note that an outer join is what `pd.concat` does by default, when there are no duplicated keys in either DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([temps.set_index('City'), countries.set_index('City')], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's try left and right joins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, a left join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps.merge(countries, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about a right join?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps.merge(countries, how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `a.merge(b, how='left')` is the same as `b.merge(a, how='right')`. The only difference is the order of the columns in the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.merge(temps, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Specifying join keys\n",
    "\n",
    "- `pandas` defaults to using the shared column(s) as join keys.\n",
    "- If there are multiple shared column names and you only want to join on one of them, **or** if there are no shared column names, then you will need to specify which columns to join on.\n",
    "- Two solutions:\n",
    "    1.  Use the `on` argument if the desired column(s) have the same names in both DataFrames.\n",
    "    2. Use the `left_on` or `left_index` argument AND the `right_on` or `right_index` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall = pd.DataFrame({\n",
    "    'PID': ['A15253545', 'A10348245', 'A13349069', 'A18485824', 'A10094857'],\n",
    "    'Student': ['Billy', 'Sally', 'Annie', 'Larry', 'Johnny'],\n",
    "    'Final': [88, 64, 91, 45, 89]\n",
    "})\n",
    "\n",
    "overall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not what we're looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exams.merge(overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, we need to tell `pandas` to look in the `'Name'` column of `exams` and `'Student'` column of `overall`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exams.merge(overall, left_on='Name', right_on='Student')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are shared column names in the two DataFrames you are merging **that you are not using as join keys**, by default `'_x'` and `'_y'` are appended to their names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exams.merge(overall, left_on='Name', right_on='Student', suffixes=('_Exam', '_Overall'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If the desired join key is in the index, assign `left_index` or `right_index` to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_by_student = overall.set_index('Student')\n",
    "overall_by_student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exams.merge(overall_by_student, left_on='Name', right_index=True, suffixes=('_Exam', '_Overall'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Many-to-one & many-to-many joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### One-to-one joins\n",
    "\n",
    "- So far in this lecture, the joins we have worked with are called **one-to-one** joins.\n",
    "- Neither the left DataFrame nor the right DataFrame contained any duplicates in the join key.\n",
    "- What if there are duplicated join keys, in one or both of the DataFrames we are merging?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Many-to-one joins\n",
    "\n",
    "- Many-to-one joins are joins where **one** of the DataFrames contains duplicate values in the join key. \n",
    "- The resulting DataFrame will preserve those duplicate entries as appropriate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>School</th>\n",
       "      <th>Years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brad</td>\n",
       "      <td>UCB</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Janine</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Marina</td>\n",
       "      <td>UIC</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Justin</td>\n",
       "      <td>OSU</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aaron</td>\n",
       "      <td>UCB</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Soohyun</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Suraj</td>\n",
       "      <td>UCB</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name School  Years\n",
       "0     Brad    UCB      8\n",
       "1   Janine   UCSD      7\n",
       "2   Marina    UIC      6\n",
       "3   Justin    OSU      4\n",
       "4    Aaron    UCB      4\n",
       "5  Soohyun   UCSD      1\n",
       "6    Suraj    UCB      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profs = pd.DataFrame(\n",
    "[['Brad', 'UCB', 8],\n",
    " ['Janine', 'UCSD', 7],\n",
    " ['Marina', 'UIC', 6],\n",
    " ['Justin', 'OSU', 4],\n",
    " ['Aaron', 'UCB', 4],\n",
    " ['Soohyun', 'UCSD', 1],\n",
    " ['Suraj', 'UCB', 1]],\n",
    "    columns=['Name', 'School', 'Years']\n",
    ")\n",
    "\n",
    "profs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abr</th>\n",
       "      <th>Full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UCSD</td>\n",
       "      <td>University of California, San Diego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UCLA</td>\n",
       "      <td>University of California, Los Angeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UCB</td>\n",
       "      <td>University of California, Berkeley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UIC</td>\n",
       "      <td>University of Illinois Chicago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Abr                                   Full\n",
       "0  UCSD    University of California, San Diego\n",
       "1  UCLA  University of California, Los Angeles\n",
       "2   UCB     University of California, Berkeley\n",
       "3   UIC         University of Illinois Chicago"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schools = pd.DataFrame({\n",
    "    'Abr': ['UCSD', 'UCLA', 'UCB', 'UIC'],\n",
    "    'Full': ['University of California, San Diego', 'University of California, Los Angeles', 'University of California, Berkeley', 'University of Illinois Chicago']\n",
    "})\n",
    "\n",
    "schools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when merging `profs` and `schools`, the information from `schools` is duplicated (`'University of California, San Diego'` appears twice and `'University of California, Berkeley'` appears three times)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profs.merge(schools, left_on='School', right_on='Abr', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Many-to-many joins\n",
    "\n",
    "Many-to-many joins are joins where both DataFrames have duplicate values in the join key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uni</th>\n",
       "      <th>dept</th>\n",
       "      <th>grad_students</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UCSD</td>\n",
       "      <td>Math</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UCSD</td>\n",
       "      <td>HDSI</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UCSD</td>\n",
       "      <td>COGS</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UCB</td>\n",
       "      <td>CS</td>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OSU</td>\n",
       "      <td>Math</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OSU</td>\n",
       "      <td>CS</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    uni  dept  grad_students\n",
       "0  UCSD  Math            205\n",
       "1  UCSD  HDSI             54\n",
       "2  UCSD  COGS            281\n",
       "3   UCB    CS            439\n",
       "4   OSU  Math            304\n",
       "5   OSU    CS            193"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "programs = pd.DataFrame({\n",
    "    'uni': ['UCSD', 'UCSD', 'UCSD', 'UCB', 'OSU', 'OSU'],\n",
    "    'dept': ['Math', 'HDSI', 'COGS', 'CS', 'Math', 'CS'],\n",
    "    'grad_students': [205, 54, 281, 439, 304, 193]\n",
    "})\n",
    "\n",
    "programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the following cell, try predicting the number of rows in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>School</th>\n",
       "      <th>Years</th>\n",
       "      <th>uni</th>\n",
       "      <th>dept</th>\n",
       "      <th>grad_students</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brad</td>\n",
       "      <td>UCB</td>\n",
       "      <td>8</td>\n",
       "      <td>UCB</td>\n",
       "      <td>CS</td>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aaron</td>\n",
       "      <td>UCB</td>\n",
       "      <td>4</td>\n",
       "      <td>UCB</td>\n",
       "      <td>CS</td>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Suraj</td>\n",
       "      <td>UCB</td>\n",
       "      <td>1</td>\n",
       "      <td>UCB</td>\n",
       "      <td>CS</td>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Janine</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>7</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>Math</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Janine</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>7</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>HDSI</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Janine</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>7</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>COGS</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Soohyun</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>1</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>Math</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Soohyun</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>1</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>HDSI</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Soohyun</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>1</td>\n",
       "      <td>UCSD</td>\n",
       "      <td>COGS</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Justin</td>\n",
       "      <td>OSU</td>\n",
       "      <td>4</td>\n",
       "      <td>OSU</td>\n",
       "      <td>Math</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Justin</td>\n",
       "      <td>OSU</td>\n",
       "      <td>4</td>\n",
       "      <td>OSU</td>\n",
       "      <td>CS</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name School  Years   uni  dept  grad_students\n",
       "0      Brad    UCB      8   UCB    CS            439\n",
       "1     Aaron    UCB      4   UCB    CS            439\n",
       "2     Suraj    UCB      1   UCB    CS            439\n",
       "3    Janine   UCSD      7  UCSD  Math            205\n",
       "4    Janine   UCSD      7  UCSD  HDSI             54\n",
       "5    Janine   UCSD      7  UCSD  COGS            281\n",
       "6   Soohyun   UCSD      1  UCSD  Math            205\n",
       "7   Soohyun   UCSD      1  UCSD  HDSI             54\n",
       "8   Soohyun   UCSD      1  UCSD  COGS            281\n",
       "9    Justin    OSU      4   OSU  Math            304\n",
       "10   Justin    OSU      4   OSU    CS            193"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profs.merge(programs, left_on='School', right_on='uni')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `merge` stitched together every UCSD row in `profs` with every UCSD row in `programs`. \n",
    "- Since there were 2 UCSD rows in `profs` and 3 in `programs`, there are $2 \\cdot 3 = 6$ UCSD rows in the output. The same applies for all other schools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: SDPD vehicle stops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aside: accessing file names programmatically\n",
    "\n",
    "- At times, you'll need to load in all of the files in a given folder.\n",
    "- `os.listdir(dirname)` returns a **list** of the names of the files in the folder `dirname`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sometimes, you'll want to extract file names that follow a specific pattern. The `pathlib` library allows you to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "file_list = list(pathlib.Path().glob('data/stops*.csv')) # glob allows for pattern matching\n",
    "file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can accomplish something similar in the command-line.\n",
    "- Place a `!` in front of a command in a Jupyter Notebook cell to run it on the command-line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data/stops*.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Loading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dfs = [pd.read_csv(file) for file in file_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in list_of_dfs:\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to concatenate these two DataFrames **vertically**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = pd.concat(list_of_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Investigating races\n",
    "\n",
    "Right now, `'subject_race'` is stored as a single character. What does `'I'` mean? `'H'`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops['subject_race'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, we have access to another dataset that describes each of the race codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races = pd.read_csv('data/race_codes.csv')\n",
    "races"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's join the distribution of races with the DataFrame of race codes.\n",
    "\n",
    "**Question:** Is this a one-to-one join?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_percentages = stops['subject_race'].value_counts(normalize=True).rename('Proportion').to_frame()\n",
    "race_percentages.merge(races, left_index=True, right_on='Race Code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **level of granularity** of the races in our data right now seems inconsistent. For instance, `'WHITE'` and `'BLACK'` are much more broad than `'FILIPINO'`, `'JAPANESE'`, and `'GUAMANIAN'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Adjusting granularity\n",
    "\n",
    "Let's try and adjust our race data so that we have a consistent level of granularity. Here's what we want to create:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>Race Code</th>\n",
    "      <th>Description</th>\n",
    "      <th>Race_Category</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>A</td>\n",
    "      <td>OTHER ASIAN</td>\n",
    "      <td>Asian</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>B</td>\n",
    "      <td>BLACK</td>\n",
    "      <td>Black</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>C</td>\n",
    "      <td>CHINESE</td>\n",
    "      <td>Asian</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>D</td>\n",
    "      <td>CAMBODIAN</td>\n",
    "      <td>Asian</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>F</td>\n",
    "      <td>FILIPINO</td>\n",
    "      <td>Asian</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "We can do this by manually defining a mapping between race codes and desired categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_dict = {'A':'Asian',\n",
    "             'B':'Black',\n",
    "             'C':'Asian',\n",
    "             'D':'Asian',\n",
    "             'F':'Asian',\n",
    "             'G':'Asian',\n",
    "             'H':'Hispanic',\n",
    "             'I':'Native American',\n",
    "             'J':'Asian',\n",
    "             'K':'Asian',\n",
    "             'L':'Asian',\n",
    "             'O':'Other',\n",
    "             'P':'Asian',\n",
    "             'S':'Asian',\n",
    "             'U':'Hawaiian',\n",
    "             'V':'Asian',\n",
    "             'W':'White',\n",
    "             'Z':'Asian'\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to replace all of the `'Race Code'`s in `races` with the above categories:\n",
    "- Use the Series `replace` method.\n",
    "- Convert the above mapping to a DataFrame and join it with `races`.\n",
    "\n",
    "Joining requires sorting, where as replacing does not. Let's go with the first option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races['Race_Category'] = races['Race Code'].replace(race_dict)\n",
    "races"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to join `stops` with `races`. An important question is, what type of join should we use (inner, outer, left, right)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops['subject_race'].isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that we don't discard the individuals whose races we don't have, we will use a **left join**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_merged = stops.merge(races, left_on='subject_race', right_on='Race Code', how='left')\n",
    "stops_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute a more meaningful distribution of races."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = stops_merged['Race_Category'].value_counts(normalize=True)\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.plot(kind='bar', figsize=(10, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a bit more helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Aside: Working with time series data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Time series ‚Äì why now?\n",
    "\n",
    "- Data is often partitioned by time. For instance, there may be one `.csv` file per day for 1 year.\n",
    "- To combine the datasets, we will need to load in the files as DataFrames and `pd.concat` the DataFrames together.\n",
    "- Note: \"time series\" is a general term and is not related to Series in `pandas`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Datetime types\n",
    "\n",
    "When working with time data, you will see two different kinds of \"times\":\n",
    "\n",
    "* **Datetimes** reference particular moments in time (e.g. November 26th, 1998 at 8:26AM).\n",
    "    - Could just be a date, e.g. September 15, 2014.\n",
    "    - Could just be a time, e.g. 4:45 AM.\n",
    "    - Datetimes typically don't keep track of timezones.\n",
    "* **Timedeltas**, or durations, reference an exact length of time (e.g. a duration of 3 hours)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The `datetime` module\n",
    "\n",
    "Python has an in-built `datetime` module, which contains `datetime` and `timedelta` types. These are much more convenient to deal with than strings that contain times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.datetime.now() + datetime.timedelta(days=3, hours=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall, Unix timestamps count the number of seconds since January 1st, 1970."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.datetime.now().timestamp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Times in `pandas`\n",
    "\n",
    "- `pd.Timestamp` is the `pandas` equivalent of `datetime`.\n",
    "- `pd.to_datetime` converts strings to `pd.Timestamp` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Timestamp(year=1998, month=11, day=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_start = pd.to_datetime('June 4th, 2022, 11:30AM')\n",
    "final_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_finish = pd.to_datetime('June 4th, 2022, 2:30PM')\n",
    "final_finish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timestamps have time-related attributes, e.g. `dayofweek`, `hour`, `min`, `sec`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_finish.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_finish.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subtracting timestamps yields `pd.Timedelta` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_finish - final_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Timestamps in DataFrames\n",
    "\n",
    "- If we create a Series of datetimes with `pd.to_datetime`, `pandas` stores them as yet *another* type:\n",
    "`np.datetime64`.\n",
    "    - These are similar to `pd.Timestamp`, but optimized for memory and speed efficiency.\n",
    "- If we access a single time, we get a `pd.Timestamp` back.\n",
    "- See [the documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "times = pd.DataFrame({'finish': pd.to_datetime(['Sun, Jan 01, 1989', \n",
    "                                                '2022-04-15T11:00', \n",
    "                                                '1/1/1970'])})\n",
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times.iloc[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times.sort_values('finish')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Exam speeds\n",
    "\n",
    "Below, we have the Final Exam starting and ending times for two sections of a course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_A = pd.DataFrame({\n",
    "    'Name': ['Annie', 'Billy', 'Sally', 'Tommy'],\n",
    "    'start_exam': ['15:00', '15:02', '15:01', '15:00'],\n",
    "    'finish_exam': ['16:00', '17:58', '17:05', '16:55']\n",
    "})\n",
    "\n",
    "times_B = pd.DataFrame({\n",
    "    'Name': ['Junior', 'Rex', 'Flash'],\n",
    "    'start_exam': ['18:00', '18:06', '19:07'],\n",
    "    'finish_exam': ['20:00', '20:50', '20:59']\n",
    "})\n",
    "\n",
    "display(times_A)\n",
    "display(times_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Who finished the exam the fastest amongst all students in the course?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Approach:\n",
    "1. Concatenate the two DataFrames.\n",
    "2. Convert the time columns to `pd.Timestamp`.\n",
    "3. Find the difference between `'finish_exam'` and `'start_exam'`.\n",
    "4. Sort.\n",
    "5. Pick the fastest exam taker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "both_versions = pd.concat([times_A, times_B])\n",
    "both_versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2\n",
    "both_versions = both_versions.assign(\n",
    "    start_exam=pd.to_datetime(both_versions['start_exam']),\n",
    "    finish_exam=pd.to_datetime(both_versions['finish_exam'])\n",
    ")\n",
    "\n",
    "both_versions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3\n",
    "both_versions = both_versions.assign(\n",
    "    elapsed=both_versions['finish_exam'] - both_versions['start_exam']\n",
    ")\n",
    "\n",
    "both_versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steps 4 and 5\n",
    "both_versions.sort_values('elapsed').iloc[0].loc['Name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary, next time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "- `pd.concat` \"stitches\" two or more DataFrames together, either vertically or horizontally.\n",
    "    - Vertically: looks at column names. Horizontally: looks at row indexes.\n",
    "- The `merge` DataFrame method **joins** two DataFrames together based on a shared column, called a join key. There are four types of joins:\n",
    "    - Inner join: keeps the **intersection** of the join keys.\n",
    "    - Outer join: keeps the **union** of the join keys.\n",
    "    - Left/right joins: keeps all of the join keys in the left/right DataFrame.\n",
    "    - In outer/left/right joins, all missing fields are filled with `NaN`s.\n",
    "- Timestamps in `pandas` are stored using `pd.Timestamp` and `pd.Timedelta` objects.\n",
    "- **Next time:** Permutation testing!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "livereveal": {
   "scroll": true,
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
